{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "input_sentence=\"diffusion works better than autoregression\"\n",
        "\n",
        "# building vocabulary\n",
        "vocab=sorted(list(set(input_sentence)))\n",
        "\n",
        "vocab_size=len(vocab)\n",
        "char_to_indx={char:i for i,char in enumerate(vocab)}\n",
        "indx_to_char={i:char for i,char in enumerate(vocab)}\n",
        "\n",
        "print(vocab_size)\n",
        "print(char_to_indx)\n",
        "print(indx_to_char)"
      ],
      "metadata": {
        "id": "KUi-63jmK-Tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b39a009-674d-45c4-e8b8-a89f9f4b5242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "{' ': 0, 'a': 1, 'b': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'k': 9, 'n': 10, 'o': 11, 'r': 12, 's': 13, 't': 14, 'u': 15, 'w': 16}\n",
            "{0: ' ', 1: 'a', 2: 'b', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'k', 10: 'n', 11: 'o', 12: 'r', 13: 's', 14: 't', 15: 'u', 16: 'w'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting text into numerical format\n",
        "\n",
        "text_to_numeric=list(char_to_indx[ch] for ch in input_sentence)\n",
        "print(text_to_numeric)\n"
      ],
      "metadata": {
        "id": "gt1Po332YVBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e339c17c-d74a-43ca-bcca-ab2ce565b03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 8, 5, 5, 15, 13, 8, 11, 10, 0, 16, 11, 12, 9, 13, 0, 2, 4, 14, 14, 4, 12, 0, 14, 7, 1, 10, 0, 1, 15, 14, 11, 12, 4, 6, 12, 4, 13, 13, 8, 11, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating input-target pair (core step of auto regression)\n",
        "x_indx=text_to_numeric[:-1]\n",
        "y_indx=text_to_numeric[1:]\n",
        "\n",
        "print(x_indx)\n",
        "print(y_indx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-cHPsKi0L2-",
        "outputId": "e370bdb1-6c7a-4641-c1fd-f71e0b2c74ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 8, 5, 5, 15, 13, 8, 11, 10, 0, 16, 11, 12, 9, 13, 0, 2, 4, 14, 14, 4, 12, 0, 14, 7, 1, 10, 0, 1, 15, 14, 11, 12, 4, 6, 12, 4, 13, 13, 8, 11]\n",
            "[8, 5, 5, 15, 13, 8, 11, 10, 0, 16, 11, 12, 9, 13, 0, 2, 4, 14, 14, 4, 12, 0, 14, 7, 1, 10, 0, 1, 15, 14, 11, 12, 4, 6, 12, 4, 13, 13, 8, 11, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode inputs\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "embedding_dimention=9 # D\n",
        "E=np.random.randn(vocab_size, embedding_dimention) # will use this embedding lookup at run time\n",
        "print(E)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml-A32mm0XJO",
        "outputId": "e52dd06c-5ff1-4667-9f1f-3bc88fdda4fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337 -0.23413696\n",
            "   1.57921282  0.76743473 -0.46947439]\n",
            " [ 0.54256004 -0.46341769 -0.46572975  0.24196227 -1.91328024 -1.72491783\n",
            "  -0.56228753 -1.01283112  0.31424733]\n",
            " [-0.90802408 -1.4123037   1.46564877 -0.2257763   0.0675282  -1.42474819\n",
            "  -0.54438272  0.11092259 -1.15099358]\n",
            " [ 0.37569802 -0.60063869 -0.29169375 -0.60170661  1.85227818 -0.01349722\n",
            "  -1.05771093  0.82254491 -1.22084365]\n",
            " [ 0.2088636  -1.95967012 -1.32818605  0.19686124  0.73846658  0.17136828\n",
            "  -0.11564828 -0.3011037  -1.47852199]\n",
            " [-0.71984421 -0.46063877  1.05712223  0.34361829 -1.76304016  0.32408397\n",
            "  -0.38508228 -0.676922    0.61167629]\n",
            " [ 1.03099952  0.93128012 -0.83921752 -0.30921238  0.33126343  0.97554513\n",
            "  -0.47917424 -0.18565898 -1.10633497]\n",
            " [-1.19620662  0.81252582  1.35624003 -0.07201012  1.0035329   0.36163603\n",
            "  -0.64511975  0.36139561  1.53803657]\n",
            " [-0.03582604  1.56464366 -2.6197451   0.8219025   0.08704707 -0.29900735\n",
            "   0.09176078 -1.98756891 -0.21967189]\n",
            " [ 0.35711257  1.47789404 -0.51827022 -0.8084936  -0.50175704  0.91540212\n",
            "   0.32875111 -0.5297602   0.51326743]\n",
            " [ 0.09707755  0.96864499 -0.70205309 -0.32766215 -0.39210815 -1.46351495\n",
            "   0.29612028  0.26105527  0.00511346]\n",
            " [-0.23458713 -1.41537074 -0.42064532 -0.34271452 -0.80227727 -0.16128571\n",
            "   0.40405086  1.8861859   0.17457781]\n",
            " [ 0.25755039 -0.07444592 -1.91877122 -0.02651388  0.06023021  2.46324211\n",
            "  -0.19236096  0.30154734 -0.03471177]\n",
            " [-1.16867804  1.14282281  0.75193303  0.79103195 -0.90938745  1.40279431\n",
            "  -1.40185106  0.58685709  2.19045563]\n",
            " [-0.99053633 -0.56629773  0.09965137 -0.50347565 -1.55066343  0.06856297\n",
            "  -1.06230371  0.47359243 -0.91942423]\n",
            " [ 1.54993441 -0.78325329 -0.32206152  0.81351722 -1.23086432  0.22745993\n",
            "   1.30714275 -1.60748323  0.18463386]\n",
            " [ 0.25988279  0.78182287 -1.23695071 -1.32045661  0.52194157  0.29698467\n",
            "   0.25049285  0.34644821 -0.68002472]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding look up at a time\n",
        "\n",
        "# for x\n",
        "# for t in range(len(x_indx)):\n",
        "#   x_t=E[x_indx[t]]\n",
        "#   print(x_t.shape) # (9,)\n",
        "\n",
        "# for y\n",
        "# for t in range(len(y_indx)):\n",
        "#   y_true_t=y_indx[t]\n",
        "#   print(y_true_t)\n"
      ],
      "metadata": {
        "id": "UZ9fDCIU6Uxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some things to remeber while working with RNN\n",
        "# vocab size = V\n",
        "# embedding size = D (number of dimention)\n",
        "# hidden size = H\n",
        "# sequence length = T (how many time steps)\n",
        "\n",
        "# so in RNN with embeddings\n",
        "# input size = embedding dimention\n",
        "# hidden size = H\n",
        "# output size = vocab size\n",
        "\n",
        "# V=vocab_size # 17\n",
        "D=embedding_dimention # 9\n",
        "H=64\n",
        "\n",
        "# parameters initialization\n",
        "# W: hidden to hidden weights\n",
        "# U: input to hidden weights\n",
        "# b: hidden bias\n",
        "# V: hidden to output weights\n",
        "# C: output bias\n",
        "\n",
        "W=np.random.randn(H,H)*0.01 # (64,64)\n",
        "U=np.random.randn(H,D)*0.01 # (64,9)\n",
        "V=np.random.randn(vocab_size,H)*0.01 # (17,64)\n",
        "\n",
        "b=np.zeros((H,1)) # (64,1)\n",
        "c=np.zeros((vocab_size,1)) # (17,1)\n"
      ],
      "metadata": {
        "id": "CdPwjQxV-tyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for t in range(len(x_indx)):\n",
        "#   x_t=E[x_indx[t]]\n",
        "#   x_t=x_t.reshape(-1,1)\n",
        "#   print(x_t.shape) # (9,1)"
      ],
      "metadata": {
        "id": "WcBlAiXACyR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# activation function\n",
        "\n",
        "def tanh(s):\n",
        "    return np.tanh(s)\n",
        "\n",
        "def derivative_tanh(s):\n",
        "    return 1-np.tanh(s)**2\n",
        "\n",
        "def softmax(o):\n",
        "    e = np.exp(o - np.max(o))\n",
        "    return e / np.sum(e, axis=0, keepdims=True)"
      ],
      "metadata": {
        "id": "pnZB04kyDppg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "# cross entropy loss function\n",
        "\n",
        "def cross_entropy_loss(y_pred, y_true):\n",
        "    eps=1e-15\n",
        "    loss=0.0\n",
        "    for t in range(len(y_true)):\n",
        "        # loss-=np.sum(y_true[t]*np.log(y_pred[t]+eps))\n",
        "        loss-=float(np.log(y_pred[t][y_true[t]]+eps))\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "RUSmKt1XEZ1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "\n",
        "def forward_pass(W,U,V,b,c,a_prev,x_indx,E):\n",
        "  s,a,o,y_pred={},{},{},{}\n",
        "  a[-1]=a_prev # (64,1)\n",
        "\n",
        "  for t in range(len(x_indx)):\n",
        "      x_t=E[x_indx[t]]\n",
        "      x_t=x_t.reshape(-1,1) # (9,1)\n",
        "\n",
        "      s[t]=W@a[t-1]+U@x_t+b # (64,1)\n",
        "      a[t]=tanh(s[t]) # (64,1)\n",
        "      o[t]=V@a[t]+c # (17,1)\n",
        "      y_pred[t]=softmax(o[t])\n",
        "\n",
        "  return s,a,o,y_pred\n"
      ],
      "metadata": {
        "id": "xtGeekrOEe7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a_prev=np.zeros((H,1)) # (64,1)\n",
        "# s,a,o,y_pred=forward_pass(W,U,V,b,c,a_prev,x_indx,E)\n"
      ],
      "metadata": {
        "id": "OsB_WJw1H3Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(y_pred[0].shape)\n",
        "# print(a[0].shape)\n",
        "# print(U.shape)"
      ],
      "metadata": {
        "id": "kdJ7t8OqJtmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_true=np.zeros((vocab_size, 1))\n",
        "# for t in range(len(y_indx)):\n",
        "#   y_true[y_indx[t]]=1\n"
      ],
      "metadata": {
        "id": "Bcc4JNp6PQt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# back propagation through time\n",
        "\n",
        "def BPTT(y_pred,U,V,W,b,c,E,x_indx,a,s,y_indx):\n",
        "\n",
        "  dL_dV=np.zeros_like(V)\n",
        "  dL_dU=np.zeros_like(U)\n",
        "  dL_dW=np.zeros_like(W)\n",
        "  dL_db=np.zeros_like(b)\n",
        "  dL_dc=np.zeros_like(c)\n",
        "\n",
        "  dL_dE=np.zeros_like(E) # for updating embedding vector\n",
        "\n",
        "  dL_da_next=np.zeros_like(a[0]) # (64,1)\n",
        "\n",
        "  for t in reversed(range(len(x_indx))):\n",
        "    x_t=E[x_indx[t]]\n",
        "    x_t=x_t.reshape(-1,1) # (9,1)\n",
        "\n",
        "    y_true=np.zeros((vocab_size, 1))\n",
        "    y_true[y_indx[t]]=1 # creating a one-hot vector for calculation\n",
        "\n",
        "    dL_do=y_pred[t] - y_true # (17,1)\n",
        "\n",
        "    # output gradients\n",
        "    dL_dV+=dL_do@a[t].T # (17,64)\n",
        "    dL_dc+=dL_do # (17,1)\n",
        "\n",
        "    # input gradients\n",
        "    dL_da=V.T @ dL_do+dL_da_next # (64,1)\n",
        "    dL_ds=dL_da*derivative_tanh(s[t]) # (64,1)\n",
        "\n",
        "    dL_db+=dL_ds # (64,1)\n",
        "    dL_dW+=dL_ds@a[t-1].T # (64,64)\n",
        "    dL_dU+=dL_ds@x_t.T # (64,9)\n",
        "\n",
        "    dL_da_next=W.T @ dL_ds # (64,1)\n",
        "    dL_dE[x_indx[t]] += (U.T @ dL_ds).flatten()\n",
        "\n",
        "  return dL_dV, dL_dU, dL_dW, dL_db, dL_dc,dL_dE\n"
      ],
      "metadata": {
        "id": "_YNHoPOUIv-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dL_dV, dL_dU, dL_dW, dL_db, dL_dc,dL_dE  =BPTT(y_pred,U,V,W,b,c,E,x_indx,a,s,y_indx)\n"
      ],
      "metadata": {
        "id": "plrPakNbTdvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's train this model\n",
        "\n",
        "epochs=100000\n",
        "lr=0.01\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # training loop\n",
        "    a_prev = np.zeros((H, 1))\n",
        "    s,a,o,y_pred_train=forward_pass(W,U,V,b,c,a_prev,x_indx,E) # forward pass\n",
        "    L_train=cross_entropy_loss(y_pred_train, y_indx)\n",
        "\n",
        "\n",
        "    dL_dV, dL_dU, dL_dW, dL_db, dL_dc,dL_dE  =BPTT(y_pred_train,U,V,W,b,c,E,x_indx,a,s,y_indx)\n",
        "\n",
        "\n",
        "    V-=lr*dL_dV\n",
        "    c-=lr*dL_dc\n",
        "    U-=lr*dL_dU\n",
        "    W-=lr*dL_dW\n",
        "    b-=lr*dL_db\n",
        "    E-=lr*dL_dE\n",
        "\n",
        "    # testing loop\n",
        "    s, a, o, y_pred_test = forward_pass(W,U,V,b,c,a_prev,x_indx,E)\n",
        "    L_test = cross_entropy_loss(y_pred=y_pred_test, y_true=y_indx)\n",
        "\n",
        "\n",
        "    if (epoch%10000)==0:\n",
        "        print(f'Epoch:{epoch}| Train Loss:{L_train}| Test Loss:{L_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15wmFGGCWwNK",
        "outputId": "ffda2def-a2cb-4727-a524-f64c78ff669c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-101944338.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  loss-=float(np.log(y_pred[t][y_true[t]]+eps))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0| Train Loss:0.0006757202829034494| Test Loss:0.0006757132276808453\n",
            "Epoch:10000| Train Loss:0.0006117394539820782| Test Loss:0.0006117336523041241\n",
            "Epoch:20000| Train Loss:0.0005586741784904275| Test Loss:0.0005586693251876425\n",
            "Epoch:30000| Train Loss:0.0005139632368323312| Test Loss:0.000513959118087044\n",
            "Epoch:40000| Train Loss:0.000475786725752939| Test Loss:0.00047578318736190845\n",
            "Epoch:50000| Train Loss:0.0004428163179338919| Test Loss:0.00044281324591800153\n",
            "Epoch:60000| Train Loss:0.00041406001857710844| Test Loss:0.00041405732688565945\n",
            "Epoch:70000| Train Loss:0.00038876220483952405| Test Loss:0.0003887598273132234\n",
            "Epoch:80000| Train Loss:0.00036633728230052546| Test Loss:0.00036633516724095526\n",
            "Epoch:90000| Train Loss:0.00034632447748295494| Test Loss:0.00034632258391487276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_text(seed_text, gen_length, E, W, U, V, b, c,\n",
        "                  char_to_indx, indx_to_char, H):\n",
        "\n",
        "    # seed_text : initial string\n",
        "    # gen_length : number of characters to generate\n",
        "\n",
        "    seed_indices = [char_to_indx[ch] for ch in seed_text]\n",
        "    a_prev = np.zeros((H, 1))\n",
        "\n",
        "    for idx in seed_indices[:-1]:\n",
        "        x_t = E[idx].reshape(-1, 1)\n",
        "        h_prev = np.tanh(W @ a_prev + U @ x_t + b)\n",
        "\n",
        "    current_idx = seed_indices[-1]\n",
        "    generated_text = seed_text\n",
        "\n",
        "    for _ in range(gen_length):\n",
        "\n",
        "        x_t = E[current_idx].reshape(-1, 1)\n",
        "\n",
        "        h_t = np.tanh(W @ h_prev + U @ x_t + b)\n",
        "\n",
        "        logits = V @ h_t + c\n",
        "\n",
        "        y_pred = softmax(logits)\n",
        "\n",
        "        # greedy sampling (other best methods also exists)\n",
        "        next_idx = np.argmax(y_pred)\n",
        "\n",
        "        # append character\n",
        "        next_char = indx_to_char[next_idx]\n",
        "        generated_text += next_char\n",
        "\n",
        "        # update\n",
        "        current_idx = next_idx\n",
        "        h_prev = h_t\n",
        "\n",
        "    return generated_text\n",
        "\n"
      ],
      "metadata": {
        "id": "mkHBXFqkyyQx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = \"diffusion works\"\n",
        "generated = generate_text(\n",
        "    seed_text=seed,\n",
        "    gen_length=40,\n",
        "    E=E,\n",
        "    W=W,\n",
        "    U=U,\n",
        "    V=V,\n",
        "    b=b,\n",
        "    c=c,\n",
        "    char_to_indx=char_to_indx,\n",
        "    indx_to_char=indx_to_char,\n",
        "    H=H\n",
        ")\n",
        "\n",
        "print(generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C378PPsMz7Ec",
        "outputId": "e08922a3-b182-4db0-d17f-73dc957e28b7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diffusion worksion works better than autoregression wor\n"
          ]
        }
      ]
    }
  ]
}