{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb065095",
   "metadata": {},
   "source": [
    "Building a Hand digit recognition using ANN from scratch\n",
    "\n",
    "dataset : self made\n",
    "\n",
    "code : self made from scratch using only NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c92ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010, 784)\n",
      "(1010,)\n"
     ]
    }
   ],
   "source": [
    "# img are represented in vector format, stored in digit_vectors\n",
    "# and corresponding labels are stores in digit_labels\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "root_dir='digits'\n",
    "files=os.listdir(root_dir)\n",
    "preprocessed=[]\n",
    "num_labels=[]\n",
    "for file in files:\n",
    "    file_path=os.path.join(root_dir, file)\n",
    "    \n",
    "    \n",
    "    for img_name in os.listdir(file_path):\n",
    "        img_path=os.path.join(file_path, img_name)\n",
    "        img=cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "        img=cv2.resize(img,(28,28))\n",
    "        preprocessed.append(img.flatten()/255.0) # normalized digit vectorization\n",
    "        num_labels.append(file) # corresponding digit labels\n",
    "\n",
    "\n",
    "digit_vectors=np.array(preprocessed)\n",
    "digit_labels=np.array(num_labels)\n",
    "print(digit_vectors.shape)  \n",
    "print(digit_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "59f9e285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69019608 0.6627451  0.68627451 ... 0.65882353 0.6745098  0.6745098 ]\n",
      " [0.68235294 0.6745098  0.67058824 ... 0.64705882 0.65882353 0.66666667]\n",
      " [0.67843137 0.6627451  0.68235294 ... 0.66666667 0.65490196 0.65490196]\n",
      " ...\n",
      " [0.60392157 0.62352941 0.6        ... 0.63921569 0.63137255 0.63529412]\n",
      " [0.60784314 0.58823529 0.61176471 ... 0.62745098 0.63529412 0.62745098]\n",
      " [0.60392157 0.60784314 0.59607843 ... 0.61960784 0.61176471 0.63529412]]\n"
     ]
    }
   ],
   "source": [
    "print(digit_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "510b3f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' ... '9' '9' '9']\n"
     ]
    }
   ],
   "source": [
    "print(digit_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c29ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing dataset into training and testing dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(digit_vectors, digit_labels,test_size=0.2,random_state=42,stratify=digit_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b269acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808, 784)\n",
      "(202, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2b8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808, 10)\n",
      "(202, 10)\n"
     ]
    }
   ],
   "source": [
    "# one hot encoder,\n",
    "# y train (808,1), but in y train, there are 10 digits (0-9)\n",
    "# so, encoded y train's size should be (808,10)\n",
    "# similary for y_test too\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(sparse_output=False)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_train_hot=enc.fit_transform(y_train)\n",
    "y_test_hot=enc.fit_transform(y_test)\n",
    "\n",
    "print(y_train_hot.shape)\n",
    "print(y_test_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066d925",
   "metadata": {},
   "source": [
    "the ANN architecture for digit recognition consist of 5 layers\n",
    "\n",
    "1 input layer (808,784), 3 hidden layer (128, 64, 32), 1 output layer (808,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "59e64bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 128)\n",
      "(1, 128)\n",
      "(128, 64)\n",
      "(1, 64)\n",
      "(64, 32)\n",
      "(1, 32)\n",
      "(32, 10)\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "# input to hidden layer 1\n",
    "# w_ip_h1=np.random.uniform(low=-1.0, high=1.0, size=(784,128))\n",
    "w_ip_h1=np.random.randn(784,128)*np.sqrt(2.0/784)\n",
    "b_ip_h1=np.zeros((1,128))\n",
    "\n",
    "# hidden layer 1 to hidden layer 2\n",
    "# w_h1_h2 = np.random.uniform(low=-1.0, high=1.0, size=(128, 64))\n",
    "w_h1_h2 = np.random.randn(128, 64)*np.sqrt(2.0/128)\n",
    "b_h1_h2 = np.zeros((1, 64))\n",
    "\n",
    "# hidden layer 2 to hidden layer 3\n",
    "# w_h2_h3 = np.random.uniform(low=-1.0, high=1.0, size=(64, 32))\n",
    "w_h2_h3 = np.random.randn(64, 32)*np.sqrt(2.0/64)\n",
    "b_h2_h3 = np.zeros((1,32))\n",
    "\n",
    "# hidden layer 3 to output layer\n",
    "# w_h3_op = np.random.uniform(low=-1.0, high=1.0, size=(32, 10))\n",
    "w_h3_op = np.random.randn(32, 10)*np.sqrt(2.0/32)\n",
    "b_h3_op = np.zeros((1,10))\n",
    "\n",
    "print(w_ip_h1.shape)\n",
    "print(b_ip_h1.shape)\n",
    "print(w_h1_h2.shape)\n",
    "print(b_h1_h2.shape)\n",
    "print(w_h2_h3.shape)\n",
    "print(b_h2_h3.shape)\n",
    "print(w_h3_op.shape)\n",
    "print(b_h3_op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c7e2a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function ReLu\n",
    "def ReLu(z):\n",
    "    # max(0,x)\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "def ReLu_derivative(z):\n",
    "    # 1 if x>0 else 0\n",
    "    return (z>0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "5ef9f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax function\n",
    "\n",
    "def softmax(logits):\n",
    "    # logits = np.clip(logits, 1e-15, 1-1e-15)  # Prevent overflow\n",
    "    logits = logits - np.max(logits, axis=1, keepdims=True)\n",
    "    expscores = np.exp(logits)\n",
    "    probs = expscores / np.sum(expscores, axis=1, keepdims=True)\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6230cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical cross entropy function\n",
    "\n",
    "def categorical_crossentropy(y_true_val, y_pred_val):\n",
    "    # forcing probablities between tiny values to prevent log(0)=NaN\n",
    "    y_pred_val = np.clip(y_pred_val, 1e-15, 1-1e-15)\n",
    "    return -np.mean(np.sum(y_true_val*np.log(y_pred_val), axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c8d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0| Train Loss: 2.366148167495323| Test Loss: 2.364842862119504\n",
      "Epoch: 1000| Train Loss: 2.2660204279675424| Test Loss: 2.2730802691210927\n",
      "Epoch: 2000| Train Loss: 2.230877960608891| Test Loss: 2.2399845417522135\n",
      "Epoch: 3000| Train Loss: 2.2102387631986993| Test Loss: 2.220480067807914\n",
      "Epoch: 4000| Train Loss: 2.189146412649585| Test Loss: 2.2014574506320708\n",
      "Epoch: 5000| Train Loss: 2.168259213108437| Test Loss: 2.181323142015241\n",
      "Epoch: 6000| Train Loss: 2.1480378917268133| Test Loss: 2.1620144950994575\n",
      "Epoch: 7000| Train Loss: 2.1275862319942833| Test Loss: 2.1423181622707754\n",
      "Epoch: 8000| Train Loss: 2.107022792203563| Test Loss: 2.122221712751712\n",
      "Epoch: 9000| Train Loss: 2.085991448362866| Test Loss: 2.1017304691229786\n"
     ]
    }
   ],
   "source": [
    "# training, testing loop\n",
    "\n",
    "lr=0.0001\n",
    "epochs=10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training\n",
    "    # forward pass\n",
    "    z1 = X_train@w_ip_h1+b_ip_h1  # (808,128)\n",
    "    a1 = ReLu(z1)  # (808,128)\n",
    "\n",
    "    z2 = a1@w_h1_h2+b_h1_h2  # (808,64)\n",
    "    a2 = ReLu(z2)  # (808,64)\n",
    "\n",
    "    z3 = a2@w_h2_h3+b_h2_h3  # (808,32)\n",
    "    a3 = ReLu(z3)  # (808,32)\n",
    "\n",
    "    z4 = a3@w_h3_op+b_h3_op  # (808,10)\n",
    "\n",
    "    # softmax probablity\n",
    "    y_pred_train=softmax(logits=z4)\n",
    "\n",
    "    # loss function\n",
    "    L_train=categorical_crossentropy(y_true_val=y_train_hot, y_pred_val=y_pred_train)\n",
    "\n",
    "    # backpropagation\n",
    "    # output layer to hidden layer 3\n",
    "    # weight gradients\n",
    "    # dL/dw_h3_op = dL/dy_pred * dy_pred/dz4 * dz4/dw_h3_op\n",
    "    # dL/dz4 = dL/dy_pred * dy_pred/dz4\n",
    "    # dL/dw_h3_op = dL/dz4 * dz4/dw_h3_op\n",
    "\n",
    "    # dL_dy_pred = y_pred - y_train_hot # (808,10)\n",
    "    # dy_pred_dz4 = y_pred - y_train_hot # (808,10)\n",
    "    # dL_dz4 = dL_dy_pred * dy_pred_dz4 # (808,10)\n",
    "\n",
    "    N=X_train.shape[0]\n",
    "    dL_dz4 = (y_pred_train - y_train_hot)/N # (808,10)\n",
    "\n",
    "\n",
    "    dz4_dw_h3_op=a3 # (808,32)\n",
    "\n",
    "    dL_dw_h3_op=dz4_dw_h3_op.T @ dL_dz4 # (32,10)\n",
    "\n",
    "\n",
    "    # bias gradients\n",
    "    # dL/db_h3_op = dL/dy_pred * dy_pred/dz4 * dz4/db_h3_op\n",
    "    # dL/dz4 = dL/dy_pred * dy_pred/dz4\n",
    "    # dL/db_h3_op = dL/dz4 * dz4/db_h3_op\n",
    "    # dz4/db_h3_op = 1\n",
    "\n",
    "    dL_db_h3_op=np.sum(dL_dz4, axis=0, keepdims=True) # (1,10)\n",
    "\n",
    "\n",
    "    # hidden layer 3 to hidden layer 2\n",
    "    # weight gradients\n",
    "    # dL/dw_h2_h3 = dL/da3 * da3/dz3 * dz3/dw_h2_h3\n",
    "    # dL/da3 = dL/dy_pred * dy_pred/dz4 * dz4/da3\n",
    "    # dL/dz4 = dL/dy_pred * dy_pred/dz4\n",
    "    # dL/da3 = dL/dz4 * dz4/da3\n",
    "    # dL/dz4 : (808,10)\n",
    "\n",
    "    dz4_da3 = w_h3_op # (32,10)\n",
    "\n",
    "    dL_da3 = dL_dz4 @ dz4_da3.T # (808,32)\n",
    "    da3_dz3 = ReLu_derivative(z3) # (808,32)\n",
    "    dz3_dw_h2_h3 = a2 # (808,64)\n",
    "\n",
    "    # dL/dz3 = dL/da3 * da3/dz3\n",
    "    dL_dz3 = dL_da3 * da3_dz3 # (808,32)\n",
    "\n",
    "\n",
    "    # dL/dw_h2_h3 = dL/dz3 * dz3/dw_h2_h3\n",
    "    dL_dw_h2_h3 = dz3_dw_h2_h3.T @ dL_dz3 # (64,32)\n",
    "\n",
    "\n",
    "    # bias gradients\n",
    "    # dL/db_h2_h3 = dL/da3 * da3/dz3 * dz3/db_h2_h3\n",
    "    # dL/db_h2_h3 = dL/dz3 * dz3/db_h2_h3\n",
    "    # dz3/db_h2_h3 = 1\n",
    "    dL_db_h2_h3 = np.sum(dL_dz3, axis=0, keepdims=True) # (1,32)\n",
    "\n",
    "\n",
    "    # hidden layer 2 to hidden layer 1\n",
    "    # weight gradients\n",
    "    # dL/dw_h1_h2 = dL/da2 * da2/dz2 * dz2/dw_h1_h2\n",
    "    # dL/da2 = dL/da3 * da3/dz3 * dz3/da2\n",
    "    # dL/da2 = dL/dz3 * dz3/da2\n",
    "    dL_dz3 = dL_da3 * da3_dz3  # (808,32)\n",
    "    dz3_da2 = w_h2_h3 # (64,32)\n",
    "    dL_da2 = dL_dz3 @ dz3_da2.T # (808,64)\n",
    "\n",
    "    da2_dz2 =  ReLu_derivative(z2) # (808,64)\n",
    "\n",
    "    # dL/dz2 = dL/da2 * da2/dz2\n",
    "    dL_dz2 = dL_da2 * da2_dz2 # (808,64)\n",
    "\n",
    "    dz2_dw_h1_h2 = a1 # (808,128)\n",
    "\n",
    "    # dL/dw_h1_h2 = dL/da2 * da2/dz2 * dz2/dw_h1_h2\n",
    "    # dL/dw_h1_h2 = dL/dz2 * dz2/dw_h1_h2\n",
    "    dL_dw_h1_h2 = dz2_dw_h1_h2.T @ dL_dz2 # (128,64)\n",
    "\n",
    "\n",
    "    # bias gradients\n",
    "    # dL/db_h1_h2 = dL/da2 * da2/dz2 * dz2/db_h1_h2\n",
    "    # dL/db_h1_h2 = dL/dz2 * dz2/db_h1_h2\n",
    "    dz2_db_h1_h2 = 1\n",
    "    dL_db_h1_h2 = np.sum(dL_dz2, axis=0, keepdims=True) # (1,64)\n",
    "\n",
    "\n",
    "    # Hidden Layer 1 to Input Layer\n",
    "    # dL/dw_ip_h1 = dL/da1 * da1/dz1 * dz1/dw_ip_h1\n",
    "    # dL/da1 = dL/da2 * da2/dz2 * dz2/da1\n",
    "    # dL/da1 = dL/dz2 * dz2/da1\n",
    "    dz2_da1 = w_h1_h2 # (128,64)\n",
    "    dL_dz2 = dL_da2 * da2_dz2  # (808,64)\n",
    "\n",
    "    dL_da1 = dL_dz2 @ dz2_da1.T # (808,128)\n",
    "\n",
    "    da1_dz1 = ReLu_derivative(z1) # (808,128)\n",
    "\n",
    "    # dL/dz1 = dL/da1 * da1/dz1\n",
    "    dL_dz1 = dL_da1 * da1_dz1 # (808,128)\n",
    "\n",
    "    dz1_dw_ip_h1 = X_train # (808,784)\n",
    "\n",
    "    # dL/dw_ip_h1 = dL/da1 * da1/dz1 * dz1/dw_ip_h1\n",
    "    # dL/dw_ip_h1 = dL/dz1 * dz1/dw_ip_h1\n",
    "    dL_dw_ip_h1 = dz1_dw_ip_h1.T @ dL_dz1 # (784,128)\n",
    "\n",
    "\n",
    "    # bias gradients\n",
    "    # dL/db_ip_h1 = dL/da1 * da1/dz1 * dz1/db_ip_h1\n",
    "    # dL/db_ip_h1 = dL/dz1 * dz1/db_ip_h1\n",
    "    dz1_db_ip_h1 = 1\n",
    "    dL_db_ip_h1 = np.sum(dL_dz1, axis=0, keepdims=True) # (1, 128)\n",
    "\n",
    "\n",
    "    # updation\n",
    "    # output to hidden 3\n",
    "    w_h3_op -= lr*dL_dw_h3_op\n",
    "    b_h3_op -= lr*dL_db_h3_op\n",
    "\n",
    "    # hidden 3 to hidden 2\n",
    "    w_h2_h3 -= lr*dL_dw_h2_h3\n",
    "    b_h2_h3 -= lr*dL_db_h2_h3\n",
    "\n",
    "    # hidden 2 to hidden 1\n",
    "    w_h1_h2 -= lr*dL_dw_h1_h2\n",
    "    b_h1_h2 -= lr*dL_db_h1_h2\n",
    "\n",
    "    # hidden 1 to input\n",
    "    w_ip_h1 -= lr*dL_dw_ip_h1\n",
    "    b_ip_h1 -= lr*dL_db_ip_h1\n",
    "\n",
    "\n",
    "    # Testing\n",
    "    # forward pass\n",
    "    z1 = X_test@w_ip_h1+b_ip_h1  # (202,128)\n",
    "    a1 = ReLu(z1)  # (202,128)\n",
    "\n",
    "    z2 = a1@w_h1_h2+b_h1_h2  # (202,64)\n",
    "    a2 = ReLu(z2)  # (202,64)\n",
    "\n",
    "    z3 = a2@w_h2_h3+b_h2_h3  # (202,32)\n",
    "    a3 = ReLu(z3)  # (202,32)\n",
    "\n",
    "    z4 = a3@w_h3_op+b_h3_op  # (202,10)\n",
    "\n",
    "    # softmax probablity\n",
    "    y_pred_test = softmax(logits=z4)\n",
    "\n",
    "    # loss function\n",
    "    L_test = categorical_crossentropy(y_true_val=y_test_hot, y_pred_val=y_pred_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if (epoch%1000)==0:\n",
    "        print(f\"Epoch: {epoch}| Train Loss: {L_train}| Test Loss: {L_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "714bc059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    }
   ],
   "source": [
    "# testing on an image\n",
    "test_root_dir='test'\n",
    "test_files=os.listdir(test_root_dir)\n",
    "\n",
    "for img in test_files:\n",
    "    test_img_path=os.path.join(test_root_dir, img)\n",
    "    test_img=cv2.imread(test_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    test_img=cv2.resize(test_img,(28,28))\n",
    "    test_img=test_img.flatten()/255.0\n",
    "\n",
    "X_test_input=test_img.reshape(1,-1) \n",
    "print(X_test_input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "814b4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_pass(X,\n",
    "                 w_ip_h1, b_ip_h1,\n",
    "                 w_h1_h2, b_h1_h2,\n",
    "                 w_h2_h3, b_h2_h3,\n",
    "                 w_h3_op, b_h3_op):\n",
    "\n",
    "    z1 = X @ w_ip_h1 + b_ip_h1\n",
    "    a1 = ReLu(z1)\n",
    "\n",
    "    z2 = a1 @ w_h1_h2 + b_h1_h2\n",
    "    a2 = ReLu(z2)\n",
    "\n",
    "    z3 = a2 @ w_h2_h3 + b_h2_h3\n",
    "    a3 = ReLu(z3)\n",
    "\n",
    "    z4 = a3 @ w_h3_op + b_h3_op\n",
    "    y_pred = softmax(z4)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e21c320b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Digit: 5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = forward_pass(\n",
    "    X_test_input,\n",
    "    w_ip_h1, b_ip_h1,\n",
    "    w_h1_h2, b_h1_h2,\n",
    "    w_h2_h3, b_h2_h3,\n",
    "    w_h3_op, b_h3_op\n",
    ")\n",
    "plt.imshow(X_test_input.reshape(28,28),cmap='gray')\n",
    "plt.show()\n",
    "print(\"Predicted Digit:\", np.argmax(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
