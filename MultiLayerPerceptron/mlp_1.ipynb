{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7304e38",
   "metadata": {},
   "source": [
    "Multi Layer Perceptron\n",
    "\n",
    "`1 input node`, `10 hidden layer neurons`, `1 output nodes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5dc6b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "x_points = np.linspace(0, 1, 10)\n",
    "noise = np.random.uniform(-0.05, 0.05, size=x_points.shape)\n",
    "x_inputs = x_points + noise\n",
    "\n",
    "# choosing as a output\n",
    "y_true=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c7598cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02509198  0.09014286  0.04639879  0.0197317  -0.06879627 -0.0688011\n",
      "  -0.08838328  0.07323523  0.020223    0.04161452]\n",
      " [-0.0958831   0.09398197  0.06648853 -0.05753218 -0.06363501 -0.0633191\n",
      "  -0.03915155  0.00495129 -0.013611   -0.04175417]\n",
      " [ 0.02237058 -0.07210123 -0.04157107 -0.02672763 -0.008786    0.05703519\n",
      "  -0.06006524  0.00284689  0.01848291 -0.09070992]\n",
      " [ 0.02150897 -0.06589518 -0.08698968  0.08977711  0.09312641  0.06167947\n",
      "  -0.03907725 -0.08046558  0.03684661 -0.0119695 ]\n",
      " [-0.07559235 -0.00096462 -0.0931223   0.08186408 -0.048244    0.03250446\n",
      "  -0.03765778  0.0040136   0.00934206 -0.06302911]\n",
      " [ 0.09391693  0.05502656  0.08789979  0.07896547  0.01958     0.08437485\n",
      "  -0.0823015  -0.06080343 -0.09095454 -0.03493393]\n",
      " [-0.02226454 -0.04573019  0.0657475  -0.02864933 -0.0438131   0.00853922\n",
      "  -0.07181516  0.0604394  -0.08508987  0.09737739]\n",
      " [ 0.05444895 -0.06025686 -0.09889558  0.06309229  0.04137147  0.04580143\n",
      "   0.05425407 -0.08519107 -0.02830685 -0.07682619]\n",
      " [ 0.07262069  0.02465963 -0.0338204  -0.08728833 -0.03780354 -0.03496334\n",
      "   0.04592124  0.02751149  0.07744255 -0.00555701]\n",
      " [-0.07608115  0.04264896  0.05215701  0.01225544  0.05419344 -0.00124088\n",
      "   0.00454657 -0.0144918  -0.09491617 -0.07842171]]\n",
      "[[-0.09371416  0.02728208 -0.0371288   0.00171414  0.08151329 -0.05014155\n",
      "  -0.01792342  0.05111023 -0.05424037 -0.08460402]]\n"
     ]
    }
   ],
   "source": [
    "# hidden layer 10 neurons\n",
    "np.random.seed(42)\n",
    "num_inputs=10\n",
    "num_neurons=10\n",
    "\n",
    "# WEIGHTS, BIAS FOR INPUT LAYER -> HIDDEN LAYER\n",
    "weights_input_hidden=np.random.uniform(low=-0.1, high=0.1,size=(num_inputs, num_neurons))\n",
    "bias_hidden=np.random.uniform(low=-0.1, high=0.1, size=(1,num_neurons))\n",
    "\n",
    "print(weights_input_hidden)\n",
    "print(bias_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "17449164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(weights_input_hidden.shape)\n",
    "print(x_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2f5f7643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid activation function\n",
    "def sigmoid_activation_function(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "797c4f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.95071431 0.73199394 0.59865848 0.15601864 0.15599452\n",
      "  0.05808361 0.86617615 0.60111501 0.70807258]]\n",
      "[[0.02058449]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# WEIGHTS, BIAS FOR HIDDEN LAYER -> OUTPUT LAYER\n",
    "np.random.seed(42)\n",
    "weights_hidden_output=np.random.rand(1,10)\n",
    "bias_output = np.random.rand(1).reshape(1,1)\n",
    "\n",
    "# weights_hidden_output=weights_hidden_output.flatten()\n",
    "print(weights_hidden_output)\n",
    "print(bias_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "df462427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0| Loss : 0.0028, y_pred : 0.9247\n",
      "Epoch 10000| Loss : 0.0005, y_pred : 0.9690\n",
      "Epoch 20000| Loss : 0.0002, y_pred : 0.9777\n",
      "Epoch 30000| Loss : 0.0002, y_pred : 0.9818\n",
      "Epoch 40000| Loss : 0.0001, y_pred : 0.9843\n",
      "Epoch 50000| Loss : 0.0001, y_pred : 0.9861\n",
      "Epoch 60000| Loss : 0.0001, y_pred : 0.9873\n",
      "Epoch 70000| Loss : 0.0001, y_pred : 0.9883\n",
      "Epoch 80000| Loss : 0.0001, y_pred : 0.9891\n",
      "Epoch 90000| Loss : 0.0001, y_pred : 0.9898\n",
      "Epoch 100000| Loss : 0.0000, y_pred : 0.9903\n",
      "Epoch 110000| Loss : 0.0000, y_pred : 0.9908\n",
      "Epoch 120000| Loss : 0.0000, y_pred : 0.9912\n",
      "Epoch 130000| Loss : 0.0000, y_pred : 0.9916\n",
      "Epoch 140000| Loss : 0.0000, y_pred : 0.9919\n",
      "Epoch 150000| Loss : 0.0000, y_pred : 0.9922\n",
      "Epoch 160000| Loss : 0.0000, y_pred : 0.9925\n",
      "Epoch 170000| Loss : 0.0000, y_pred : 0.9927\n",
      "Epoch 180000| Loss : 0.0000, y_pred : 0.9929\n",
      "Epoch 190000| Loss : 0.0000, y_pred : 0.9931\n",
      "Epoch 200000| Loss : 0.0000, y_pred : 0.9933\n",
      "Epoch 210000| Loss : 0.0000, y_pred : 0.9935\n",
      "Epoch 220000| Loss : 0.0000, y_pred : 0.9937\n",
      "Epoch 230000| Loss : 0.0000, y_pred : 0.9938\n",
      "Epoch 240000| Loss : 0.0000, y_pred : 0.9939\n",
      "Epoch 250000| Loss : 0.0000, y_pred : 0.9941\n",
      "Epoch 260000| Loss : 0.0000, y_pred : 0.9942\n",
      "Epoch 270000| Loss : 0.0000, y_pred : 0.9943\n",
      "Epoch 280000| Loss : 0.0000, y_pred : 0.9944\n",
      "Epoch 290000| Loss : 0.0000, y_pred : 0.9945\n",
      "Epoch 300000| Loss : 0.0000, y_pred : 0.9946\n",
      "Epoch 310000| Loss : 0.0000, y_pred : 0.9947\n",
      "Epoch 320000| Loss : 0.0000, y_pred : 0.9948\n",
      "Epoch 330000| Loss : 0.0000, y_pred : 0.9949\n",
      "Epoch 340000| Loss : 0.0000, y_pred : 0.9950\n",
      "Epoch 350000| Loss : 0.0000, y_pred : 0.9950\n",
      "Epoch 360000| Loss : 0.0000, y_pred : 0.9951\n",
      "Epoch 370000| Loss : 0.0000, y_pred : 0.9952\n",
      "Epoch 380000| Loss : 0.0000, y_pred : 0.9953\n",
      "Epoch 390000| Loss : 0.0000, y_pred : 0.9953\n",
      "Epoch 400000| Loss : 0.0000, y_pred : 0.9954\n",
      "Epoch 410000| Loss : 0.0000, y_pred : 0.9954\n",
      "Epoch 420000| Loss : 0.0000, y_pred : 0.9955\n",
      "Epoch 430000| Loss : 0.0000, y_pred : 0.9956\n",
      "Epoch 440000| Loss : 0.0000, y_pred : 0.9956\n",
      "Epoch 450000| Loss : 0.0000, y_pred : 0.9957\n",
      "Epoch 460000| Loss : 0.0000, y_pred : 0.9957\n",
      "Epoch 470000| Loss : 0.0000, y_pred : 0.9958\n",
      "Epoch 480000| Loss : 0.0000, y_pred : 0.9958\n",
      "Epoch 490000| Loss : 0.0000, y_pred : 0.9959\n",
      "Epoch 500000| Loss : 0.0000, y_pred : 0.9959\n",
      "Epoch 510000| Loss : 0.0000, y_pred : 0.9959\n",
      "Epoch 520000| Loss : 0.0000, y_pred : 0.9960\n",
      "Epoch 530000| Loss : 0.0000, y_pred : 0.9960\n",
      "Epoch 540000| Loss : 0.0000, y_pred : 0.9961\n",
      "Epoch 550000| Loss : 0.0000, y_pred : 0.9961\n",
      "Epoch 560000| Loss : 0.0000, y_pred : 0.9961\n",
      "Epoch 570000| Loss : 0.0000, y_pred : 0.9962\n",
      "Epoch 580000| Loss : 0.0000, y_pred : 0.9962\n",
      "Epoch 590000| Loss : 0.0000, y_pred : 0.9962\n",
      "Epoch 600000| Loss : 0.0000, y_pred : 0.9963\n",
      "Epoch 610000| Loss : 0.0000, y_pred : 0.9963\n",
      "Epoch 620000| Loss : 0.0000, y_pred : 0.9963\n",
      "Epoch 630000| Loss : 0.0000, y_pred : 0.9964\n",
      "Epoch 640000| Loss : 0.0000, y_pred : 0.9964\n",
      "Epoch 650000| Loss : 0.0000, y_pred : 0.9964\n",
      "Epoch 660000| Loss : 0.0000, y_pred : 0.9965\n",
      "Epoch 670000| Loss : 0.0000, y_pred : 0.9965\n",
      "Epoch 680000| Loss : 0.0000, y_pred : 0.9965\n",
      "Epoch 690000| Loss : 0.0000, y_pred : 0.9965\n",
      "Epoch 700000| Loss : 0.0000, y_pred : 0.9966\n",
      "Epoch 710000| Loss : 0.0000, y_pred : 0.9966\n",
      "Epoch 720000| Loss : 0.0000, y_pred : 0.9966\n",
      "Epoch 730000| Loss : 0.0000, y_pred : 0.9966\n",
      "Epoch 740000| Loss : 0.0000, y_pred : 0.9967\n",
      "Epoch 750000| Loss : 0.0000, y_pred : 0.9967\n",
      "Epoch 760000| Loss : 0.0000, y_pred : 0.9967\n",
      "Epoch 770000| Loss : 0.0000, y_pred : 0.9967\n",
      "Epoch 780000| Loss : 0.0000, y_pred : 0.9968\n",
      "Epoch 790000| Loss : 0.0000, y_pred : 0.9968\n",
      "Epoch 800000| Loss : 0.0000, y_pred : 0.9968\n",
      "Epoch 810000| Loss : 0.0000, y_pred : 0.9968\n",
      "Epoch 820000| Loss : 0.0000, y_pred : 0.9968\n",
      "Epoch 830000| Loss : 0.0000, y_pred : 0.9969\n",
      "Epoch 840000| Loss : 0.0000, y_pred : 0.9969\n",
      "Epoch 850000| Loss : 0.0000, y_pred : 0.9969\n",
      "Epoch 860000| Loss : 0.0000, y_pred : 0.9969\n",
      "Epoch 870000| Loss : 0.0000, y_pred : 0.9969\n",
      "Epoch 880000| Loss : 0.0000, y_pred : 0.9970\n",
      "Epoch 890000| Loss : 0.0000, y_pred : 0.9970\n",
      "Epoch 900000| Loss : 0.0000, y_pred : 0.9970\n",
      "Epoch 910000| Loss : 0.0000, y_pred : 0.9970\n",
      "Epoch 920000| Loss : 0.0000, y_pred : 0.9970\n",
      "Epoch 930000| Loss : 0.0000, y_pred : 0.9971\n",
      "Epoch 940000| Loss : 0.0000, y_pred : 0.9971\n",
      "Epoch 950000| Loss : 0.0000, y_pred : 0.9971\n",
      "Epoch 960000| Loss : 0.0000, y_pred : 0.9971\n",
      "Epoch 970000| Loss : 0.0000, y_pred : 0.9971\n",
      "Epoch 980000| Loss : 0.0000, y_pred : 0.9971\n",
      "Epoch 990000| Loss : 0.0000, y_pred : 0.9971\n"
     ]
    }
   ],
   "source": [
    "epochs=1000000\n",
    "learning_rate=0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # FORWARD PASS\n",
    "    # INPUT LAYER -> HIDDEN LAYER\n",
    "    z_hidden=weights_input_hidden@x_inputs+bias_hidden\n",
    "    a_hidden=sigmoid_activation_function(z_hidden)\n",
    "\n",
    "    # HIDDEN LAYER -> OUTPUT LAYER\n",
    "    z_output=a_hidden@weights_hidden_output.T+bias_output\n",
    "    y_pred=sigmoid_activation_function(z_output)\n",
    "\n",
    "    # loss (L)\n",
    "    loss=0.5*(y_pred-y_true)**2\n",
    "\n",
    "    # BACKPROPAGATION\n",
    "    # # FROM OUTPUT LAYER -> HIDDEN LAYER\n",
    "\n",
    "    # # dL/dw = dL/dy^ * dy^/dZ * dZ/dw\n",
    "    dl_dy_pred=(y_pred - y_true)\n",
    "    dy_pred_dz_output=y_pred*(1-y_pred)\n",
    "    dz_output_dw_hidden_output=a_hidden\n",
    "\n",
    "    dl_dw_hidden_output=dl_dy_pred*dy_pred_dz_output*dz_output_dw_hidden_output # weights gradients\n",
    "\n",
    "    # # dL/db = dL/dy^ * dy^/dZ * dZ/db\n",
    "    dl_db_output=dl_dy_pred*dy_pred_dz_output*1 # bias gradients\n",
    "\n",
    "    # weights, bias updation\n",
    "    weights_hidden_output-=learning_rate*dl_dw_hidden_output\n",
    "    bias_output-=learning_rate*dl_db_output\n",
    "\n",
    "\n",
    "    # FROM HIDDEN LAYER -> INPUT LAYER\n",
    "    # hidden layer gradients\n",
    "    # dL/dW=dL/da_hidden * da_hidden/dz_hidden * dz_hidden/dw_input_hidden\n",
    "    # dL/da_hidden = dL/dy^ * dy^/dZ * dZ/da_hidden\n",
    "\n",
    "    dl_da_hidden = dl_dy_pred*dy_pred_dz_output*weights_hidden_output \n",
    "    da_hidden_dz_hidden=a_hidden*(1-a_hidden)\n",
    "    # dl/dz_hidden\n",
    "    dl_dz_hidden=dl_da_hidden*da_hidden_dz_hidden\n",
    "    dz_hidden_dw_input_hidden=x_inputs\n",
    "\n",
    "    dl_dw_input_hidden=np.outer(dl_dz_hidden,dz_hidden_dw_input_hidden)\n",
    "    dl_db_hidden=dl_dz_hidden\n",
    "\n",
    "    # weights, bias updation\n",
    "    weights_input_hidden-=learning_rate*dl_dw_input_hidden\n",
    "    bias_hidden-=learning_rate*dl_db_hidden\n",
    "\n",
    "\n",
    "    if epoch%10000==0:\n",
    "        \n",
    "        # converting to scaler if needed\n",
    "        loss_val = loss.item() if np.ndim(loss) == 0 or loss.size == 1 else np.mean(loss)\n",
    "        y_pred_val = y_pred.item() if np.ndim(y_pred) == 0 or y_pred.size == 1 else np.mean(y_pred)\n",
    "\n",
    "        print(f\"Epoch {epoch}| Loss : {loss_val:.4f}, y_pred : {y_pred_val:.4f}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
