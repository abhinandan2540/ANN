{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4286818c",
   "metadata": {},
   "source": [
    "Let's build a Multi-Layer Perceptron having\n",
    "\n",
    "`1 Input Layer`, `3 Hidden Layer (16, 8, 4)`, `1 Output Layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceca4e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "X=np.random.rand(1).reshape(-1,1)\n",
    "Y_true=1\n",
    "\n",
    "print(X.shape)\n",
    "print(Y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e67fb",
   "metadata": {},
   "source": [
    "weights, bias for `Input Layer` to `Hidden Layer 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f008efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16)\n",
      "[[-0.25091976  0.90142861  0.46398788  0.19731697 -0.68796272 -0.68801096\n",
      "  -0.88383278  0.73235229  0.20223002  0.41614516 -0.95883101  0.9398197\n",
      "   0.66488528 -0.57532178 -0.63635007 -0.63319098]]\n",
      "(1, 16)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "w_input_hidden1=np.random.uniform(low=-1.0, high=1.0, size=(1,16))\n",
    "# b_input_hidden1=np.random.uniform(low=-1.0, high=1.0, size=(1,16))\n",
    "# initializing bias from zeros\n",
    "b_input_hidden1=np.zeros((1,16))\n",
    "\n",
    "\n",
    "print(w_input_hidden1.shape)\n",
    "print(w_input_hidden1)\n",
    "print(b_input_hidden1.shape)\n",
    "print(b_input_hidden1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f14f0d",
   "metadata": {},
   "source": [
    "weights, bias for `Hidden Layer 1` to `Hidden Layer 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13895f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8)\n",
      "[[-0.25091976  0.90142861  0.46398788  0.19731697 -0.68796272 -0.68801096\n",
      "  -0.88383278  0.73235229]\n",
      " [ 0.20223002  0.41614516 -0.95883101  0.9398197   0.66488528 -0.57532178\n",
      "  -0.63635007 -0.63319098]\n",
      " [-0.39151551  0.04951286 -0.13610996 -0.41754172  0.22370579 -0.72101228\n",
      "  -0.4157107  -0.26727631]\n",
      " [-0.08786003  0.57035192 -0.60065244  0.02846888  0.18482914 -0.90709917\n",
      "   0.2150897  -0.65895175]\n",
      " [-0.86989681  0.89777107  0.93126407  0.6167947  -0.39077246 -0.80465577\n",
      "   0.36846605 -0.11969501]\n",
      " [-0.75592353 -0.00964618 -0.93122296  0.8186408  -0.48244004  0.32504457\n",
      "  -0.37657785  0.04013604]\n",
      " [ 0.09342056 -0.63029109  0.93916926  0.55026565  0.87899788  0.7896547\n",
      "   0.19579996  0.84374847]\n",
      " [-0.823015   -0.60803428 -0.90954542 -0.34933934 -0.22264542 -0.45730194\n",
      "   0.65747502 -0.28649335]\n",
      " [-0.43813098  0.08539217 -0.71815155  0.60439396 -0.85089871  0.97377387\n",
      "   0.54448954 -0.60256864]\n",
      " [-0.98895577  0.63092286  0.41371469  0.45801434  0.54254069 -0.8519107\n",
      "  -0.28306854 -0.76826188]\n",
      " [ 0.72620685  0.24659625 -0.33820395 -0.8728833  -0.37803536 -0.34963336\n",
      "   0.45921236  0.27511494]\n",
      " [ 0.77442549 -0.05557015 -0.76081151  0.42648957  0.5215701   0.1225544\n",
      "   0.54193436 -0.01240881]\n",
      " [ 0.04546566 -0.14491796 -0.94916175 -0.78421715 -0.93714163  0.27282082\n",
      "  -0.37128804  0.01714138]\n",
      " [ 0.81513295 -0.50141554 -0.17923415  0.51110228 -0.54240367 -0.84604018\n",
      "  -0.42049709 -0.67755743]\n",
      " [ 0.8593953   0.61624076  0.26680751  0.74292118  0.60734415 -0.62685988\n",
      "   0.785118    0.07868448]\n",
      " [ 0.61488031  0.7921826  -0.36399305 -0.77989615 -0.54412967 -0.14578442\n",
      "   0.63602953  0.72146117]]\n",
      "(1, 8)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "w_hidden1_hidden2=np.random.uniform(low=-1.0, high=1.0, size=(16,8))\n",
    "# b_hidden1_hidden2=np.random.uniform(low=-1.0, high=1.0, size=(1,8))\n",
    "b_hidden1_hidden2 = np.zeros((1, 8))\n",
    "\n",
    "print(w_hidden1_hidden2.shape)\n",
    "print(w_hidden1_hidden2)\n",
    "print(b_hidden1_hidden2.shape)\n",
    "print(b_hidden1_hidden2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50cc83d",
   "metadata": {},
   "source": [
    "weights, bias for `Hidden Layer 2` to `Hidden Layer 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ea1bf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "[[-0.25091976  0.90142861  0.46398788  0.19731697]\n",
      " [-0.68796272 -0.68801096 -0.88383278  0.73235229]\n",
      " [ 0.20223002  0.41614516 -0.95883101  0.9398197 ]\n",
      " [ 0.66488528 -0.57532178 -0.63635007 -0.63319098]\n",
      " [-0.39151551  0.04951286 -0.13610996 -0.41754172]\n",
      " [ 0.22370579 -0.72101228 -0.4157107  -0.26727631]\n",
      " [-0.08786003  0.57035192 -0.60065244  0.02846888]\n",
      " [ 0.18482914 -0.90709917  0.2150897  -0.65895175]]\n",
      "(1, 4)\n",
      "[[0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "w_hidden2_hidden3 = np.random.uniform(low=-1.0, high=1.0, size=(8,4))\n",
    "# b_hidden2_hidden3 = np.random.uniform(low=-1.0, high=1.0, size=(1, 4))\n",
    "b_hidden2_hidden3 = np.zeros((1, 4))\n",
    "\n",
    "print(w_hidden2_hidden3.shape)\n",
    "print(w_hidden2_hidden3)\n",
    "print(b_hidden2_hidden3.shape)\n",
    "print(b_hidden2_hidden3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84287d8b",
   "metadata": {},
   "source": [
    "weights bias for `Hidden Layer 3` to `Output Layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0acbc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "[[-0.25091976]\n",
      " [ 0.90142861]\n",
      " [ 0.46398788]\n",
      " [ 0.19731697]]\n",
      "(1, 1)\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "w_hidden3_output=np.random.uniform(low=-1.0, high=1.0, size=(4,1))\n",
    "# b_hidden3_output=np.random.uniform(low=-1.0, high=1.0, size=(1,1))\n",
    "b_hidden3_output = np.zeros((1, 1))\n",
    "\n",
    "print(w_hidden3_output.shape)\n",
    "print(w_hidden3_output)\n",
    "print(b_hidden3_output.shape)\n",
    "print(b_hidden3_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899af47b",
   "metadata": {},
   "source": [
    "`Sigmoid Activation` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8eeb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid_Activation(z):\n",
    "    return 1/(1+np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940ec3b6",
   "metadata": {},
   "source": [
    "Model Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a276f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from input -> hidden layer 1\n",
    "z_input_hidden1=X@w_input_hidden1+b_input_hidden1 # (1,16)\n",
    "a_input_hidden1=Sigmoid_Activation(z_input_hidden1) # (1,16)\n",
    "\n",
    "# hidden layer 1 -> hidden layer 2\n",
    "z_hidden1_hidden2=a_input_hidden1@w_hidden1_hidden2+b_hidden1_hidden2 # (1,8)\n",
    "a_hidden1_hidden2=Sigmoid_Activation(z_hidden1_hidden2) # (1,8)\n",
    "\n",
    "# hidden layer 2 -> hidden layer 3\n",
    "z_hidden2_hidden3=a_hidden1_hidden2@w_hidden2_hidden3+b_hidden2_hidden3\n",
    "a_hidden2_hidden3=Sigmoid_Activation(z_hidden2_hidden3) # (1,4)\n",
    "\n",
    "# hidden layer 3 -> output layer\n",
    "z_hidden3_output=a_hidden2_hidden3@w_hidden3_output+b_hidden3_output\n",
    "Y_pred=Sigmoid_Activation(z_hidden3_output) # (1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074c900",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3da6194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100| Loss : 0.066495 | Y_pred : 0.635321\n",
      "Epoch : 200| Loss : 0.054968 | Y_pred : 0.668434\n",
      "Epoch : 300| Loss : 0.046045 | Y_pred : 0.696537\n",
      "Epoch : 400| Loss : 0.039079 | Y_pred : 0.720433\n",
      "Epoch : 500| Loss : 0.033579 | Y_pred : 0.740850\n",
      "Epoch : 600| Loss : 0.029184 | Y_pred : 0.758404\n",
      "Epoch : 700| Loss : 0.025628 | Y_pred : 0.773603\n",
      "Epoch : 800| Loss : 0.022715 | Y_pred : 0.786857\n",
      "Epoch : 900| Loss : 0.020302 | Y_pred : 0.798496\n",
      "Epoch : 1000| Loss : 0.018281 | Y_pred : 0.808787\n",
      "Epoch : 1100| Loss : 0.016572 | Y_pred : 0.817943\n",
      "Epoch : 1200| Loss : 0.015114 | Y_pred : 0.826137\n",
      "Epoch : 1300| Loss : 0.013859 | Y_pred : 0.833511\n",
      "Epoch : 1400| Loss : 0.012771 | Y_pred : 0.840180\n",
      "Epoch : 1500| Loss : 0.011821 | Y_pred : 0.846242\n",
      "Epoch : 1600| Loss : 0.010985 | Y_pred : 0.851774\n",
      "Epoch : 1700| Loss : 0.010247 | Y_pred : 0.856845\n",
      "Epoch : 1800| Loss : 0.009590 | Y_pred : 0.861509\n",
      "Epoch : 1900| Loss : 0.009003 | Y_pred : 0.865815\n",
      "Epoch : 2000| Loss : 0.008476 | Y_pred : 0.869802\n",
      "Epoch : 2100| Loss : 0.008000 | Y_pred : 0.873507\n",
      "Epoch : 2200| Loss : 0.007570 | Y_pred : 0.876957\n",
      "Epoch : 2300| Loss : 0.007178 | Y_pred : 0.880180\n",
      "Epoch : 2400| Loss : 0.006822 | Y_pred : 0.883197\n",
      "Epoch : 2500| Loss : 0.006495 | Y_pred : 0.886028\n",
      "Epoch : 2600| Loss : 0.006195 | Y_pred : 0.888691\n",
      "Epoch : 2700| Loss : 0.005919 | Y_pred : 0.891200\n",
      "Epoch : 2800| Loss : 0.005664 | Y_pred : 0.893568\n",
      "Epoch : 2900| Loss : 0.005428 | Y_pred : 0.895809\n",
      "Epoch : 3000| Loss : 0.005209 | Y_pred : 0.897932\n",
      "Epoch : 3100| Loss : 0.005005 | Y_pred : 0.899946\n",
      "Epoch : 3200| Loss : 0.004816 | Y_pred : 0.901860\n",
      "Epoch : 3300| Loss : 0.004639 | Y_pred : 0.903682\n",
      "Epoch : 3400| Loss : 0.004473 | Y_pred : 0.905418\n",
      "Epoch : 3500| Loss : 0.004318 | Y_pred : 0.907075\n",
      "Epoch : 3600| Loss : 0.004172 | Y_pred : 0.908658\n",
      "Epoch : 3700| Loss : 0.004034 | Y_pred : 0.910172\n",
      "Epoch : 3800| Loss : 0.003905 | Y_pred : 0.911622\n",
      "Epoch : 3900| Loss : 0.003783 | Y_pred : 0.913012\n",
      "Epoch : 4000| Loss : 0.003668 | Y_pred : 0.914346\n",
      "Epoch : 4100| Loss : 0.003559 | Y_pred : 0.915627\n",
      "Epoch : 4200| Loss : 0.003456 | Y_pred : 0.916859\n",
      "Epoch : 4300| Loss : 0.003358 | Y_pred : 0.918044\n",
      "Epoch : 4400| Loss : 0.003265 | Y_pred : 0.919186\n",
      "Epoch : 4500| Loss : 0.003177 | Y_pred : 0.920286\n",
      "Epoch : 4600| Loss : 0.003093 | Y_pred : 0.921347\n",
      "Epoch : 4700| Loss : 0.003013 | Y_pred : 0.922371\n",
      "Epoch : 4800| Loss : 0.002937 | Y_pred : 0.923361\n",
      "Epoch : 4900| Loss : 0.002864 | Y_pred : 0.924318\n",
      "Epoch : 5000| Loss : 0.002794 | Y_pred : 0.925243\n",
      "Epoch : 5100| Loss : 0.002728 | Y_pred : 0.926139\n",
      "Epoch : 5200| Loss : 0.002664 | Y_pred : 0.927006\n",
      "Epoch : 5300| Loss : 0.002603 | Y_pred : 0.927847\n",
      "Epoch : 5400| Loss : 0.002545 | Y_pred : 0.928662\n",
      "Epoch : 5500| Loss : 0.002488 | Y_pred : 0.929453\n",
      "Epoch : 5600| Loss : 0.002435 | Y_pred : 0.930221\n",
      "Epoch : 5700| Loss : 0.002383 | Y_pred : 0.930967\n",
      "Epoch : 5800| Loss : 0.002333 | Y_pred : 0.931691\n",
      "Epoch : 5900| Loss : 0.002285 | Y_pred : 0.932396\n",
      "Epoch : 6000| Loss : 0.002239 | Y_pred : 0.933081\n",
      "Epoch : 6100| Loss : 0.002195 | Y_pred : 0.933748\n",
      "Epoch : 6200| Loss : 0.002152 | Y_pred : 0.934397\n",
      "Epoch : 6300| Loss : 0.002111 | Y_pred : 0.935029\n",
      "Epoch : 6400| Loss : 0.002071 | Y_pred : 0.935645\n",
      "Epoch : 6500| Loss : 0.002032 | Y_pred : 0.936246\n",
      "Epoch : 6600| Loss : 0.001995 | Y_pred : 0.936831\n",
      "Epoch : 6700| Loss : 0.001959 | Y_pred : 0.937402\n",
      "Epoch : 6800| Loss : 0.001925 | Y_pred : 0.937959\n",
      "Epoch : 6900| Loss : 0.001891 | Y_pred : 0.938503\n",
      "Epoch : 7000| Loss : 0.001858 | Y_pred : 0.939035\n",
      "Epoch : 7100| Loss : 0.001827 | Y_pred : 0.939554\n",
      "Epoch : 7200| Loss : 0.001796 | Y_pred : 0.940061\n",
      "Epoch : 7300| Loss : 0.001767 | Y_pred : 0.940556\n",
      "Epoch : 7400| Loss : 0.001738 | Y_pred : 0.941041\n",
      "Epoch : 7500| Loss : 0.001710 | Y_pred : 0.941515\n",
      "Epoch : 7600| Loss : 0.001683 | Y_pred : 0.941979\n",
      "Epoch : 7700| Loss : 0.001657 | Y_pred : 0.942433\n",
      "Epoch : 7800| Loss : 0.001632 | Y_pred : 0.942877\n",
      "Epoch : 7900| Loss : 0.001607 | Y_pred : 0.943312\n",
      "Epoch : 8000| Loss : 0.001583 | Y_pred : 0.943738\n",
      "Epoch : 8100| Loss : 0.001559 | Y_pred : 0.944156\n",
      "Epoch : 8200| Loss : 0.001537 | Y_pred : 0.944565\n",
      "Epoch : 8300| Loss : 0.001514 | Y_pred : 0.944966\n",
      "Epoch : 8400| Loss : 0.001493 | Y_pred : 0.945359\n",
      "Epoch : 8500| Loss : 0.001472 | Y_pred : 0.945744\n",
      "Epoch : 8600| Loss : 0.001451 | Y_pred : 0.946123\n",
      "Epoch : 8700| Loss : 0.001431 | Y_pred : 0.946494\n",
      "Epoch : 8800| Loss : 0.001412 | Y_pred : 0.946858\n",
      "Epoch : 8900| Loss : 0.001393 | Y_pred : 0.947215\n",
      "Epoch : 9000| Loss : 0.001375 | Y_pred : 0.947566\n",
      "Epoch : 9100| Loss : 0.001357 | Y_pred : 0.947911\n",
      "Epoch : 9200| Loss : 0.001339 | Y_pred : 0.948249\n",
      "Epoch : 9300| Loss : 0.001322 | Y_pred : 0.948581\n",
      "Epoch : 9400| Loss : 0.001305 | Y_pred : 0.948908\n",
      "Epoch : 9500| Loss : 0.001289 | Y_pred : 0.949229\n",
      "Epoch : 9600| Loss : 0.001273 | Y_pred : 0.949544\n",
      "Epoch : 9700| Loss : 0.001257 | Y_pred : 0.949854\n",
      "Epoch : 9800| Loss : 0.001242 | Y_pred : 0.950159\n",
      "Epoch : 9900| Loss : 0.001227 | Y_pred : 0.950459\n",
      "Epoch : 10000| Loss : 0.001213 | Y_pred : 0.950754\n",
      "Epoch : 10100| Loss : 0.001198 | Y_pred : 0.951044\n",
      "Epoch : 10200| Loss : 0.001184 | Y_pred : 0.951329\n",
      "Epoch : 10300| Loss : 0.001171 | Y_pred : 0.951610\n",
      "Epoch : 10400| Loss : 0.001157 | Y_pred : 0.951887\n",
      "Epoch : 10500| Loss : 0.001144 | Y_pred : 0.952159\n",
      "Epoch : 10600| Loss : 0.001132 | Y_pred : 0.952427\n",
      "Epoch : 10700| Loss : 0.001119 | Y_pred : 0.952691\n",
      "Epoch : 10800| Loss : 0.001107 | Y_pred : 0.952951\n",
      "Epoch : 10900| Loss : 0.001095 | Y_pred : 0.953207\n",
      "Epoch : 11000| Loss : 0.001083 | Y_pred : 0.953459\n",
      "Epoch : 11100| Loss : 0.001072 | Y_pred : 0.953707\n",
      "Epoch : 11200| Loss : 0.001060 | Y_pred : 0.953952\n",
      "Epoch : 11300| Loss : 0.001049 | Y_pred : 0.954193\n",
      "Epoch : 11400| Loss : 0.001038 | Y_pred : 0.954431\n",
      "Epoch : 11500| Loss : 0.001028 | Y_pred : 0.954665\n",
      "Epoch : 11600| Loss : 0.001017 | Y_pred : 0.954896\n",
      "Epoch : 11700| Loss : 0.001007 | Y_pred : 0.955124\n",
      "Epoch : 11800| Loss : 0.000997 | Y_pred : 0.955348\n",
      "Epoch : 11900| Loss : 0.000987 | Y_pred : 0.955570\n",
      "Epoch : 12000| Loss : 0.000977 | Y_pred : 0.955788\n",
      "Epoch : 12100| Loss : 0.000968 | Y_pred : 0.956004\n",
      "Epoch : 12200| Loss : 0.000958 | Y_pred : 0.956217\n",
      "Epoch : 12300| Loss : 0.000949 | Y_pred : 0.956426\n",
      "Epoch : 12400| Loss : 0.000940 | Y_pred : 0.956633\n",
      "Epoch : 12500| Loss : 0.000931 | Y_pred : 0.956838\n",
      "Epoch : 12600| Loss : 0.000923 | Y_pred : 0.957040\n",
      "Epoch : 12700| Loss : 0.000914 | Y_pred : 0.957239\n",
      "Epoch : 12800| Loss : 0.000906 | Y_pred : 0.957435\n",
      "Epoch : 12900| Loss : 0.000898 | Y_pred : 0.957629\n",
      "Epoch : 13000| Loss : 0.000890 | Y_pred : 0.957821\n",
      "Epoch : 13100| Loss : 0.000882 | Y_pred : 0.958010\n",
      "Epoch : 13200| Loss : 0.000874 | Y_pred : 0.958197\n",
      "Epoch : 13300| Loss : 0.000866 | Y_pred : 0.958381\n",
      "Epoch : 13400| Loss : 0.000858 | Y_pred : 0.958564\n",
      "Epoch : 13500| Loss : 0.000851 | Y_pred : 0.958744\n",
      "Epoch : 13600| Loss : 0.000844 | Y_pred : 0.958922\n",
      "Epoch : 13700| Loss : 0.000836 | Y_pred : 0.959098\n",
      "Epoch : 13800| Loss : 0.000829 | Y_pred : 0.959271\n",
      "Epoch : 13900| Loss : 0.000822 | Y_pred : 0.959443\n",
      "Epoch : 14000| Loss : 0.000816 | Y_pred : 0.959613\n",
      "Epoch : 14100| Loss : 0.000809 | Y_pred : 0.959781\n",
      "Epoch : 14200| Loss : 0.000802 | Y_pred : 0.959946\n",
      "Epoch : 14300| Loss : 0.000796 | Y_pred : 0.960110\n",
      "Epoch : 14400| Loss : 0.000789 | Y_pred : 0.960272\n",
      "Epoch : 14500| Loss : 0.000783 | Y_pred : 0.960433\n",
      "Epoch : 14600| Loss : 0.000777 | Y_pred : 0.960591\n",
      "Epoch : 14700| Loss : 0.000770 | Y_pred : 0.960748\n",
      "Epoch : 14800| Loss : 0.000764 | Y_pred : 0.960903\n",
      "Epoch : 14900| Loss : 0.000758 | Y_pred : 0.961056\n",
      "Epoch : 15000| Loss : 0.000752 | Y_pred : 0.961208\n",
      "Epoch : 15100| Loss : 0.000747 | Y_pred : 0.961357\n",
      "Epoch : 15200| Loss : 0.000741 | Y_pred : 0.961506\n",
      "Epoch : 15300| Loss : 0.000735 | Y_pred : 0.961653\n",
      "Epoch : 15400| Loss : 0.000730 | Y_pred : 0.961798\n",
      "Epoch : 15500| Loss : 0.000724 | Y_pred : 0.961941\n",
      "Epoch : 15600| Loss : 0.000719 | Y_pred : 0.962084\n",
      "Epoch : 15700| Loss : 0.000713 | Y_pred : 0.962224\n",
      "Epoch : 15800| Loss : 0.000708 | Y_pred : 0.962364\n",
      "Epoch : 15900| Loss : 0.000703 | Y_pred : 0.962501\n",
      "Epoch : 16000| Loss : 0.000698 | Y_pred : 0.962638\n",
      "Epoch : 16100| Loss : 0.000693 | Y_pred : 0.962773\n",
      "Epoch : 16200| Loss : 0.000688 | Y_pred : 0.962907\n",
      "Epoch : 16300| Loss : 0.000683 | Y_pred : 0.963039\n",
      "Epoch : 16400| Loss : 0.000678 | Y_pred : 0.963170\n",
      "Epoch : 16500| Loss : 0.000673 | Y_pred : 0.963300\n",
      "Epoch : 16600| Loss : 0.000669 | Y_pred : 0.963428\n",
      "Epoch : 16700| Loss : 0.000664 | Y_pred : 0.963555\n",
      "Epoch : 16800| Loss : 0.000660 | Y_pred : 0.963681\n",
      "Epoch : 16900| Loss : 0.000655 | Y_pred : 0.963806\n",
      "Epoch : 17000| Loss : 0.000651 | Y_pred : 0.963930\n",
      "Epoch : 17100| Loss : 0.000646 | Y_pred : 0.964052\n",
      "Epoch : 17200| Loss : 0.000642 | Y_pred : 0.964173\n",
      "Epoch : 17300| Loss : 0.000637 | Y_pred : 0.964293\n",
      "Epoch : 17400| Loss : 0.000633 | Y_pred : 0.964412\n",
      "Epoch : 17500| Loss : 0.000629 | Y_pred : 0.964530\n",
      "Epoch : 17600| Loss : 0.000625 | Y_pred : 0.964647\n",
      "Epoch : 17700| Loss : 0.000621 | Y_pred : 0.964763\n",
      "Epoch : 17800| Loss : 0.000617 | Y_pred : 0.964877\n",
      "Epoch : 17900| Loss : 0.000613 | Y_pred : 0.964991\n",
      "Epoch : 18000| Loss : 0.000609 | Y_pred : 0.965104\n",
      "Epoch : 18100| Loss : 0.000605 | Y_pred : 0.965215\n",
      "Epoch : 18200| Loss : 0.000601 | Y_pred : 0.965326\n",
      "Epoch : 18300| Loss : 0.000597 | Y_pred : 0.965435\n",
      "Epoch : 18400| Loss : 0.000594 | Y_pred : 0.965544\n",
      "Epoch : 18500| Loss : 0.000590 | Y_pred : 0.965652\n",
      "Epoch : 18600| Loss : 0.000586 | Y_pred : 0.965758\n",
      "Epoch : 18700| Loss : 0.000583 | Y_pred : 0.965864\n",
      "Epoch : 18800| Loss : 0.000579 | Y_pred : 0.965969\n",
      "Epoch : 18900| Loss : 0.000576 | Y_pred : 0.966073\n",
      "Epoch : 19000| Loss : 0.000572 | Y_pred : 0.966176\n",
      "Epoch : 19100| Loss : 0.000569 | Y_pred : 0.966279\n",
      "Epoch : 19200| Loss : 0.000565 | Y_pred : 0.966380\n",
      "Epoch : 19300| Loss : 0.000562 | Y_pred : 0.966480\n",
      "Epoch : 19400| Loss : 0.000558 | Y_pred : 0.966580\n",
      "Epoch : 19500| Loss : 0.000555 | Y_pred : 0.966679\n",
      "Epoch : 19600| Loss : 0.000552 | Y_pred : 0.966777\n",
      "Epoch : 19700| Loss : 0.000549 | Y_pred : 0.966874\n",
      "Epoch : 19800| Loss : 0.000545 | Y_pred : 0.966971\n",
      "Epoch : 19900| Loss : 0.000542 | Y_pred : 0.967066\n",
      "Epoch : 20000| Loss : 0.000539 | Y_pred : 0.967161\n",
      "Epoch : 20100| Loss : 0.000536 | Y_pred : 0.967255\n",
      "Epoch : 20200| Loss : 0.000533 | Y_pred : 0.967349\n",
      "Epoch : 20300| Loss : 0.000530 | Y_pred : 0.967441\n",
      "Epoch : 20400| Loss : 0.000527 | Y_pred : 0.967533\n",
      "Epoch : 20500| Loss : 0.000524 | Y_pred : 0.967624\n",
      "Epoch : 20600| Loss : 0.000521 | Y_pred : 0.967715\n",
      "Epoch : 20700| Loss : 0.000518 | Y_pred : 0.967804\n",
      "Epoch : 20800| Loss : 0.000515 | Y_pred : 0.967893\n",
      "Epoch : 20900| Loss : 0.000513 | Y_pred : 0.967982\n",
      "Epoch : 21000| Loss : 0.000510 | Y_pred : 0.968069\n",
      "Epoch : 21100| Loss : 0.000507 | Y_pred : 0.968156\n",
      "Epoch : 21200| Loss : 0.000504 | Y_pred : 0.968242\n",
      "Epoch : 21300| Loss : 0.000502 | Y_pred : 0.968328\n",
      "Epoch : 21400| Loss : 0.000499 | Y_pred : 0.968413\n",
      "Epoch : 21500| Loss : 0.000496 | Y_pred : 0.968497\n",
      "Epoch : 21600| Loss : 0.000494 | Y_pred : 0.968581\n",
      "Epoch : 21700| Loss : 0.000491 | Y_pred : 0.968664\n",
      "Epoch : 21800| Loss : 0.000488 | Y_pred : 0.968747\n",
      "Epoch : 21900| Loss : 0.000486 | Y_pred : 0.968829\n",
      "Epoch : 22000| Loss : 0.000483 | Y_pred : 0.968910\n",
      "Epoch : 22100| Loss : 0.000481 | Y_pred : 0.968991\n",
      "Epoch : 22200| Loss : 0.000478 | Y_pred : 0.969071\n",
      "Epoch : 22300| Loss : 0.000476 | Y_pred : 0.969150\n",
      "Epoch : 22400| Loss : 0.000473 | Y_pred : 0.969229\n",
      "Epoch : 22500| Loss : 0.000471 | Y_pred : 0.969308\n",
      "Epoch : 22600| Loss : 0.000469 | Y_pred : 0.969385\n",
      "Epoch : 22700| Loss : 0.000466 | Y_pred : 0.969463\n",
      "Epoch : 22800| Loss : 0.000464 | Y_pred : 0.969539\n",
      "Epoch : 22900| Loss : 0.000462 | Y_pred : 0.969615\n",
      "Epoch : 23000| Loss : 0.000459 | Y_pred : 0.969691\n",
      "Epoch : 23100| Loss : 0.000457 | Y_pred : 0.969766\n",
      "Epoch : 23200| Loss : 0.000455 | Y_pred : 0.969841\n",
      "Epoch : 23300| Loss : 0.000453 | Y_pred : 0.969915\n",
      "Epoch : 23400| Loss : 0.000450 | Y_pred : 0.969988\n",
      "Epoch : 23500| Loss : 0.000448 | Y_pred : 0.970061\n",
      "Epoch : 23600| Loss : 0.000446 | Y_pred : 0.970134\n",
      "Epoch : 23700| Loss : 0.000444 | Y_pred : 0.970206\n",
      "Epoch : 23800| Loss : 0.000442 | Y_pred : 0.970278\n",
      "Epoch : 23900| Loss : 0.000440 | Y_pred : 0.970349\n",
      "Epoch : 24000| Loss : 0.000438 | Y_pred : 0.970419\n",
      "Epoch : 24100| Loss : 0.000435 | Y_pred : 0.970489\n",
      "Epoch : 24200| Loss : 0.000433 | Y_pred : 0.970559\n",
      "Epoch : 24300| Loss : 0.000431 | Y_pred : 0.970628\n",
      "Epoch : 24400| Loss : 0.000429 | Y_pred : 0.970697\n",
      "Epoch : 24500| Loss : 0.000427 | Y_pred : 0.970765\n",
      "Epoch : 24600| Loss : 0.000425 | Y_pred : 0.970833\n",
      "Epoch : 24700| Loss : 0.000423 | Y_pred : 0.970900\n",
      "Epoch : 24800| Loss : 0.000421 | Y_pred : 0.970967\n",
      "Epoch : 24900| Loss : 0.000420 | Y_pred : 0.971034\n",
      "Epoch : 25000| Loss : 0.000418 | Y_pred : 0.971100\n",
      "Epoch : 25100| Loss : 0.000416 | Y_pred : 0.971166\n",
      "Epoch : 25200| Loss : 0.000414 | Y_pred : 0.971231\n",
      "Epoch : 25300| Loss : 0.000412 | Y_pred : 0.971296\n",
      "Epoch : 25400| Loss : 0.000410 | Y_pred : 0.971360\n",
      "Epoch : 25500| Loss : 0.000408 | Y_pred : 0.971424\n",
      "Epoch : 25600| Loss : 0.000406 | Y_pred : 0.971488\n",
      "Epoch : 25700| Loss : 0.000405 | Y_pred : 0.971551\n",
      "Epoch : 25800| Loss : 0.000403 | Y_pred : 0.971614\n",
      "Epoch : 25900| Loss : 0.000401 | Y_pred : 0.971676\n",
      "Epoch : 26000| Loss : 0.000399 | Y_pred : 0.971738\n",
      "Epoch : 26100| Loss : 0.000398 | Y_pred : 0.971800\n",
      "Epoch : 26200| Loss : 0.000396 | Y_pred : 0.971861\n",
      "Epoch : 26300| Loss : 0.000394 | Y_pred : 0.971922\n",
      "Epoch : 26400| Loss : 0.000392 | Y_pred : 0.971983\n",
      "Epoch : 26500| Loss : 0.000391 | Y_pred : 0.972043\n",
      "Epoch : 26600| Loss : 0.000389 | Y_pred : 0.972103\n",
      "Epoch : 26700| Loss : 0.000387 | Y_pred : 0.972162\n",
      "Epoch : 26800| Loss : 0.000386 | Y_pred : 0.972221\n",
      "Epoch : 26900| Loss : 0.000384 | Y_pred : 0.972280\n",
      "Epoch : 27000| Loss : 0.000383 | Y_pred : 0.972338\n",
      "Epoch : 27100| Loss : 0.000381 | Y_pred : 0.972396\n",
      "Epoch : 27200| Loss : 0.000379 | Y_pred : 0.972454\n",
      "Epoch : 27300| Loss : 0.000378 | Y_pred : 0.972511\n",
      "Epoch : 27400| Loss : 0.000376 | Y_pred : 0.972568\n",
      "Epoch : 27500| Loss : 0.000375 | Y_pred : 0.972625\n",
      "Epoch : 27600| Loss : 0.000373 | Y_pred : 0.972681\n",
      "Epoch : 27700| Loss : 0.000372 | Y_pred : 0.972737\n",
      "Epoch : 27800| Loss : 0.000370 | Y_pred : 0.972793\n",
      "Epoch : 27900| Loss : 0.000369 | Y_pred : 0.972848\n",
      "Epoch : 28000| Loss : 0.000367 | Y_pred : 0.972903\n",
      "Epoch : 28100| Loss : 0.000366 | Y_pred : 0.972958\n",
      "Epoch : 28200| Loss : 0.000364 | Y_pred : 0.973012\n",
      "Epoch : 28300| Loss : 0.000363 | Y_pred : 0.973067\n",
      "Epoch : 28400| Loss : 0.000361 | Y_pred : 0.973120\n",
      "Epoch : 28500| Loss : 0.000360 | Y_pred : 0.973174\n",
      "Epoch : 28600| Loss : 0.000358 | Y_pred : 0.973227\n",
      "Epoch : 28700| Loss : 0.000357 | Y_pred : 0.973280\n",
      "Epoch : 28800| Loss : 0.000356 | Y_pred : 0.973333\n",
      "Epoch : 28900| Loss : 0.000354 | Y_pred : 0.973385\n",
      "Epoch : 29000| Loss : 0.000353 | Y_pred : 0.973437\n",
      "Epoch : 29100| Loss : 0.000351 | Y_pred : 0.973489\n",
      "Epoch : 29200| Loss : 0.000350 | Y_pred : 0.973540\n",
      "Epoch : 29300| Loss : 0.000349 | Y_pred : 0.973591\n",
      "Epoch : 29400| Loss : 0.000347 | Y_pred : 0.973642\n",
      "Epoch : 29500| Loss : 0.000346 | Y_pred : 0.973693\n",
      "Epoch : 29600| Loss : 0.000345 | Y_pred : 0.973743\n",
      "Epoch : 29700| Loss : 0.000343 | Y_pred : 0.973793\n",
      "Epoch : 29800| Loss : 0.000342 | Y_pred : 0.973843\n",
      "Epoch : 29900| Loss : 0.000341 | Y_pred : 0.973893\n",
      "Epoch : 30000| Loss : 0.000340 | Y_pred : 0.973942\n",
      "Epoch : 30100| Loss : 0.000338 | Y_pred : 0.973991\n",
      "Epoch : 30200| Loss : 0.000337 | Y_pred : 0.974040\n",
      "Epoch : 30300| Loss : 0.000336 | Y_pred : 0.974088\n",
      "Epoch : 30400| Loss : 0.000334 | Y_pred : 0.974136\n",
      "Epoch : 30500| Loss : 0.000333 | Y_pred : 0.974184\n",
      "Epoch : 30600| Loss : 0.000332 | Y_pred : 0.974232\n",
      "Epoch : 30700| Loss : 0.000331 | Y_pred : 0.974279\n",
      "Epoch : 30800| Loss : 0.000330 | Y_pred : 0.974327\n",
      "Epoch : 30900| Loss : 0.000328 | Y_pred : 0.974374\n",
      "Epoch : 31000| Loss : 0.000327 | Y_pred : 0.974420\n",
      "Epoch : 31100| Loss : 0.000326 | Y_pred : 0.974467\n",
      "Epoch : 31200| Loss : 0.000325 | Y_pred : 0.974513\n",
      "Epoch : 31300| Loss : 0.000324 | Y_pred : 0.974559\n",
      "Epoch : 31400| Loss : 0.000322 | Y_pred : 0.974605\n",
      "Epoch : 31500| Loss : 0.000321 | Y_pred : 0.974650\n",
      "Epoch : 31600| Loss : 0.000320 | Y_pred : 0.974696\n",
      "Epoch : 31700| Loss : 0.000319 | Y_pred : 0.974741\n",
      "Epoch : 31800| Loss : 0.000318 | Y_pred : 0.974786\n",
      "Epoch : 31900| Loss : 0.000317 | Y_pred : 0.974830\n",
      "Epoch : 32000| Loss : 0.000316 | Y_pred : 0.974875\n",
      "Epoch : 32100| Loss : 0.000315 | Y_pred : 0.974919\n",
      "Epoch : 32200| Loss : 0.000313 | Y_pred : 0.974963\n",
      "Epoch : 32300| Loss : 0.000312 | Y_pred : 0.975007\n",
      "Epoch : 32400| Loss : 0.000311 | Y_pred : 0.975050\n",
      "Epoch : 32500| Loss : 0.000310 | Y_pred : 0.975093\n",
      "Epoch : 32600| Loss : 0.000309 | Y_pred : 0.975137\n",
      "Epoch : 32700| Loss : 0.000308 | Y_pred : 0.975179\n",
      "Epoch : 32800| Loss : 0.000307 | Y_pred : 0.975222\n",
      "Epoch : 32900| Loss : 0.000306 | Y_pred : 0.975265\n",
      "Epoch : 33000| Loss : 0.000305 | Y_pred : 0.975307\n",
      "Epoch : 33100| Loss : 0.000304 | Y_pred : 0.975349\n",
      "Epoch : 33200| Loss : 0.000303 | Y_pred : 0.975391\n",
      "Epoch : 33300| Loss : 0.000302 | Y_pred : 0.975432\n",
      "Epoch : 33400| Loss : 0.000301 | Y_pred : 0.975474\n",
      "Epoch : 33500| Loss : 0.000300 | Y_pred : 0.975515\n",
      "Epoch : 33600| Loss : 0.000299 | Y_pred : 0.975556\n",
      "Epoch : 33700| Loss : 0.000298 | Y_pred : 0.975597\n",
      "Epoch : 33800| Loss : 0.000297 | Y_pred : 0.975638\n",
      "Epoch : 33900| Loss : 0.000296 | Y_pred : 0.975678\n",
      "Epoch : 34000| Loss : 0.000295 | Y_pred : 0.975718\n",
      "Epoch : 34100| Loss : 0.000294 | Y_pred : 0.975759\n",
      "Epoch : 34200| Loss : 0.000293 | Y_pred : 0.975799\n",
      "Epoch : 34300| Loss : 0.000292 | Y_pred : 0.975838\n",
      "Epoch : 34400| Loss : 0.000291 | Y_pred : 0.975878\n",
      "Epoch : 34500| Loss : 0.000290 | Y_pred : 0.975917\n",
      "Epoch : 34600| Loss : 0.000289 | Y_pred : 0.975956\n",
      "Epoch : 34700| Loss : 0.000288 | Y_pred : 0.975995\n",
      "Epoch : 34800| Loss : 0.000287 | Y_pred : 0.976034\n",
      "Epoch : 34900| Loss : 0.000286 | Y_pred : 0.976073\n",
      "Epoch : 35000| Loss : 0.000285 | Y_pred : 0.976111\n",
      "Epoch : 35100| Loss : 0.000284 | Y_pred : 0.976150\n",
      "Epoch : 35200| Loss : 0.000284 | Y_pred : 0.976188\n",
      "Epoch : 35300| Loss : 0.000283 | Y_pred : 0.976226\n",
      "Epoch : 35400| Loss : 0.000282 | Y_pred : 0.976263\n",
      "Epoch : 35500| Loss : 0.000281 | Y_pred : 0.976301\n",
      "Epoch : 35600| Loss : 0.000280 | Y_pred : 0.976338\n",
      "Epoch : 35700| Loss : 0.000279 | Y_pred : 0.976376\n",
      "Epoch : 35800| Loss : 0.000278 | Y_pred : 0.976413\n",
      "Epoch : 35900| Loss : 0.000277 | Y_pred : 0.976450\n",
      "Epoch : 36000| Loss : 0.000276 | Y_pred : 0.976486\n",
      "Epoch : 36100| Loss : 0.000276 | Y_pred : 0.976523\n",
      "Epoch : 36200| Loss : 0.000275 | Y_pred : 0.976559\n",
      "Epoch : 36300| Loss : 0.000274 | Y_pred : 0.976596\n",
      "Epoch : 36400| Loss : 0.000273 | Y_pred : 0.976632\n",
      "Epoch : 36500| Loss : 0.000272 | Y_pred : 0.976668\n",
      "Epoch : 36600| Loss : 0.000271 | Y_pred : 0.976704\n",
      "Epoch : 36700| Loss : 0.000271 | Y_pred : 0.976739\n",
      "Epoch : 36800| Loss : 0.000270 | Y_pred : 0.976775\n",
      "Epoch : 36900| Loss : 0.000269 | Y_pred : 0.976810\n",
      "Epoch : 37000| Loss : 0.000268 | Y_pred : 0.976845\n",
      "Epoch : 37100| Loss : 0.000267 | Y_pred : 0.976880\n",
      "Epoch : 37200| Loss : 0.000266 | Y_pred : 0.976915\n",
      "Epoch : 37300| Loss : 0.000266 | Y_pred : 0.976950\n",
      "Epoch : 37400| Loss : 0.000265 | Y_pred : 0.976984\n",
      "Epoch : 37500| Loss : 0.000264 | Y_pred : 0.977019\n",
      "Epoch : 37600| Loss : 0.000263 | Y_pred : 0.977053\n",
      "Epoch : 37700| Loss : 0.000262 | Y_pred : 0.977087\n",
      "Epoch : 37800| Loss : 0.000262 | Y_pred : 0.977121\n",
      "Epoch : 37900| Loss : 0.000261 | Y_pred : 0.977155\n",
      "Epoch : 38000| Loss : 0.000260 | Y_pred : 0.977189\n",
      "Epoch : 38100| Loss : 0.000259 | Y_pred : 0.977223\n",
      "Epoch : 38200| Loss : 0.000259 | Y_pred : 0.977256\n",
      "Epoch : 38300| Loss : 0.000258 | Y_pred : 0.977289\n",
      "Epoch : 38400| Loss : 0.000257 | Y_pred : 0.977322\n",
      "Epoch : 38500| Loss : 0.000256 | Y_pred : 0.977355\n",
      "Epoch : 38600| Loss : 0.000256 | Y_pred : 0.977388\n",
      "Epoch : 38700| Loss : 0.000255 | Y_pred : 0.977421\n",
      "Epoch : 38800| Loss : 0.000254 | Y_pred : 0.977454\n",
      "Epoch : 38900| Loss : 0.000253 | Y_pred : 0.977486\n",
      "Epoch : 39000| Loss : 0.000253 | Y_pred : 0.977518\n",
      "Epoch : 39100| Loss : 0.000252 | Y_pred : 0.977551\n",
      "Epoch : 39200| Loss : 0.000251 | Y_pred : 0.977583\n",
      "Epoch : 39300| Loss : 0.000251 | Y_pred : 0.977615\n",
      "Epoch : 39400| Loss : 0.000250 | Y_pred : 0.977647\n",
      "Epoch : 39500| Loss : 0.000249 | Y_pred : 0.977678\n",
      "Epoch : 39600| Loss : 0.000248 | Y_pred : 0.977710\n",
      "Epoch : 39700| Loss : 0.000248 | Y_pred : 0.977741\n",
      "Epoch : 39800| Loss : 0.000247 | Y_pred : 0.977773\n",
      "Epoch : 39900| Loss : 0.000246 | Y_pred : 0.977804\n",
      "Epoch : 40000| Loss : 0.000246 | Y_pred : 0.977835\n",
      "Epoch : 40100| Loss : 0.000245 | Y_pred : 0.977866\n",
      "Epoch : 40200| Loss : 0.000244 | Y_pred : 0.977897\n",
      "Epoch : 40300| Loss : 0.000244 | Y_pred : 0.977927\n",
      "Epoch : 40400| Loss : 0.000243 | Y_pred : 0.977958\n",
      "Epoch : 40500| Loss : 0.000242 | Y_pred : 0.977988\n",
      "Epoch : 40600| Loss : 0.000242 | Y_pred : 0.978019\n",
      "Epoch : 40700| Loss : 0.000241 | Y_pred : 0.978049\n",
      "Epoch : 40800| Loss : 0.000240 | Y_pred : 0.978079\n",
      "Epoch : 40900| Loss : 0.000240 | Y_pred : 0.978109\n",
      "Epoch : 41000| Loss : 0.000239 | Y_pred : 0.978139\n",
      "Epoch : 41100| Loss : 0.000238 | Y_pred : 0.978168\n",
      "Epoch : 41200| Loss : 0.000238 | Y_pred : 0.978198\n",
      "Epoch : 41300| Loss : 0.000237 | Y_pred : 0.978228\n",
      "Epoch : 41400| Loss : 0.000236 | Y_pred : 0.978257\n",
      "Epoch : 41500| Loss : 0.000236 | Y_pred : 0.978286\n",
      "Epoch : 41600| Loss : 0.000235 | Y_pred : 0.978315\n",
      "Epoch : 41700| Loss : 0.000234 | Y_pred : 0.978345\n",
      "Epoch : 41800| Loss : 0.000234 | Y_pred : 0.978374\n",
      "Epoch : 41900| Loss : 0.000233 | Y_pred : 0.978402\n",
      "Epoch : 42000| Loss : 0.000233 | Y_pred : 0.978431\n",
      "Epoch : 42100| Loss : 0.000232 | Y_pred : 0.978460\n",
      "Epoch : 42200| Loss : 0.000231 | Y_pred : 0.978488\n",
      "Epoch : 42300| Loss : 0.000231 | Y_pred : 0.978517\n",
      "Epoch : 42400| Loss : 0.000230 | Y_pred : 0.978545\n",
      "Epoch : 42500| Loss : 0.000230 | Y_pred : 0.978573\n",
      "Epoch : 42600| Loss : 0.000229 | Y_pred : 0.978601\n",
      "Epoch : 42700| Loss : 0.000228 | Y_pred : 0.978629\n",
      "Epoch : 42800| Loss : 0.000228 | Y_pred : 0.978657\n",
      "Epoch : 42900| Loss : 0.000227 | Y_pred : 0.978685\n",
      "Epoch : 43000| Loss : 0.000227 | Y_pred : 0.978713\n",
      "Epoch : 43100| Loss : 0.000226 | Y_pred : 0.978740\n",
      "Epoch : 43200| Loss : 0.000225 | Y_pred : 0.978768\n",
      "Epoch : 43300| Loss : 0.000225 | Y_pred : 0.978795\n",
      "Epoch : 43400| Loss : 0.000224 | Y_pred : 0.978822\n",
      "Epoch : 43500| Loss : 0.000224 | Y_pred : 0.978849\n",
      "Epoch : 43600| Loss : 0.000223 | Y_pred : 0.978876\n",
      "Epoch : 43700| Loss : 0.000223 | Y_pred : 0.978903\n",
      "Epoch : 43800| Loss : 0.000222 | Y_pred : 0.978930\n",
      "Epoch : 43900| Loss : 0.000221 | Y_pred : 0.978957\n",
      "Epoch : 44000| Loss : 0.000221 | Y_pred : 0.978984\n",
      "Epoch : 44100| Loss : 0.000220 | Y_pred : 0.979010\n",
      "Epoch : 44200| Loss : 0.000220 | Y_pred : 0.979037\n",
      "Epoch : 44300| Loss : 0.000219 | Y_pred : 0.979063\n",
      "Epoch : 44400| Loss : 0.000219 | Y_pred : 0.979090\n",
      "Epoch : 44500| Loss : 0.000218 | Y_pred : 0.979116\n",
      "Epoch : 44600| Loss : 0.000218 | Y_pred : 0.979142\n",
      "Epoch : 44700| Loss : 0.000217 | Y_pred : 0.979168\n",
      "Epoch : 44800| Loss : 0.000216 | Y_pred : 0.979194\n",
      "Epoch : 44900| Loss : 0.000216 | Y_pred : 0.979220\n",
      "Epoch : 45000| Loss : 0.000215 | Y_pred : 0.979245\n",
      "Epoch : 45100| Loss : 0.000215 | Y_pred : 0.979271\n",
      "Epoch : 45200| Loss : 0.000214 | Y_pred : 0.979297\n",
      "Epoch : 45300| Loss : 0.000214 | Y_pred : 0.979322\n",
      "Epoch : 45400| Loss : 0.000213 | Y_pred : 0.979347\n",
      "Epoch : 45500| Loss : 0.000213 | Y_pred : 0.979373\n",
      "Epoch : 45600| Loss : 0.000212 | Y_pred : 0.979398\n",
      "Epoch : 45700| Loss : 0.000212 | Y_pred : 0.979423\n",
      "Epoch : 45800| Loss : 0.000211 | Y_pred : 0.979448\n",
      "Epoch : 45900| Loss : 0.000211 | Y_pred : 0.979473\n",
      "Epoch : 46000| Loss : 0.000210 | Y_pred : 0.979498\n",
      "Epoch : 46100| Loss : 0.000210 | Y_pred : 0.979523\n",
      "Epoch : 46200| Loss : 0.000209 | Y_pred : 0.979547\n",
      "Epoch : 46300| Loss : 0.000209 | Y_pred : 0.979572\n",
      "Epoch : 46400| Loss : 0.000208 | Y_pred : 0.979596\n",
      "Epoch : 46500| Loss : 0.000208 | Y_pred : 0.979621\n",
      "Epoch : 46600| Loss : 0.000207 | Y_pred : 0.979645\n",
      "Epoch : 46700| Loss : 0.000207 | Y_pred : 0.979669\n",
      "Epoch : 46800| Loss : 0.000206 | Y_pred : 0.979694\n",
      "Epoch : 46900| Loss : 0.000206 | Y_pred : 0.979718\n",
      "Epoch : 47000| Loss : 0.000205 | Y_pred : 0.979742\n",
      "Epoch : 47100| Loss : 0.000205 | Y_pred : 0.979766\n",
      "Epoch : 47200| Loss : 0.000204 | Y_pred : 0.979789\n",
      "Epoch : 47300| Loss : 0.000204 | Y_pred : 0.979813\n",
      "Epoch : 47400| Loss : 0.000203 | Y_pred : 0.979837\n",
      "Epoch : 47500| Loss : 0.000203 | Y_pred : 0.979861\n",
      "Epoch : 47600| Loss : 0.000202 | Y_pred : 0.979884\n",
      "Epoch : 47700| Loss : 0.000202 | Y_pred : 0.979908\n",
      "Epoch : 47800| Loss : 0.000201 | Y_pred : 0.979931\n",
      "Epoch : 47900| Loss : 0.000201 | Y_pred : 0.979954\n",
      "Epoch : 48000| Loss : 0.000200 | Y_pred : 0.979977\n",
      "Epoch : 48100| Loss : 0.000200 | Y_pred : 0.980001\n",
      "Epoch : 48200| Loss : 0.000200 | Y_pred : 0.980024\n",
      "Epoch : 48300| Loss : 0.000199 | Y_pred : 0.980047\n",
      "Epoch : 48400| Loss : 0.000199 | Y_pred : 0.980070\n",
      "Epoch : 48500| Loss : 0.000198 | Y_pred : 0.980092\n",
      "Epoch : 48600| Loss : 0.000198 | Y_pred : 0.980115\n",
      "Epoch : 48700| Loss : 0.000197 | Y_pred : 0.980138\n",
      "Epoch : 48800| Loss : 0.000197 | Y_pred : 0.980161\n",
      "Epoch : 48900| Loss : 0.000196 | Y_pred : 0.980183\n",
      "Epoch : 49000| Loss : 0.000196 | Y_pred : 0.980206\n",
      "Epoch : 49100| Loss : 0.000195 | Y_pred : 0.980228\n",
      "Epoch : 49200| Loss : 0.000195 | Y_pred : 0.980250\n",
      "Epoch : 49300| Loss : 0.000195 | Y_pred : 0.980273\n",
      "Epoch : 49400| Loss : 0.000194 | Y_pred : 0.980295\n",
      "Epoch : 49500| Loss : 0.000194 | Y_pred : 0.980317\n",
      "Epoch : 49600| Loss : 0.000193 | Y_pred : 0.980339\n",
      "Epoch : 49700| Loss : 0.000193 | Y_pred : 0.980361\n",
      "Epoch : 49800| Loss : 0.000192 | Y_pred : 0.980383\n",
      "Epoch : 49900| Loss : 0.000192 | Y_pred : 0.980405\n",
      "Epoch : 50000| Loss : 0.000192 | Y_pred : 0.980426\n",
      "Epoch : 50100| Loss : 0.000191 | Y_pred : 0.980448\n",
      "Epoch : 50200| Loss : 0.000191 | Y_pred : 0.980470\n",
      "Epoch : 50300| Loss : 0.000190 | Y_pred : 0.980491\n",
      "Epoch : 50400| Loss : 0.000190 | Y_pred : 0.980513\n",
      "Epoch : 50500| Loss : 0.000189 | Y_pred : 0.980534\n",
      "Epoch : 50600| Loss : 0.000189 | Y_pred : 0.980556\n",
      "Epoch : 50700| Loss : 0.000189 | Y_pred : 0.980577\n",
      "Epoch : 50800| Loss : 0.000188 | Y_pred : 0.980598\n",
      "Epoch : 50900| Loss : 0.000188 | Y_pred : 0.980619\n",
      "Epoch : 51000| Loss : 0.000187 | Y_pred : 0.980640\n",
      "Epoch : 51100| Loss : 0.000187 | Y_pred : 0.980661\n",
      "Epoch : 51200| Loss : 0.000187 | Y_pred : 0.980682\n",
      "Epoch : 51300| Loss : 0.000186 | Y_pred : 0.980703\n",
      "Epoch : 51400| Loss : 0.000186 | Y_pred : 0.980724\n",
      "Epoch : 51500| Loss : 0.000185 | Y_pred : 0.980745\n",
      "Epoch : 51600| Loss : 0.000185 | Y_pred : 0.980765\n",
      "Epoch : 51700| Loss : 0.000185 | Y_pred : 0.980786\n",
      "Epoch : 51800| Loss : 0.000184 | Y_pred : 0.980807\n",
      "Epoch : 51900| Loss : 0.000184 | Y_pred : 0.980827\n",
      "Epoch : 52000| Loss : 0.000183 | Y_pred : 0.980848\n",
      "Epoch : 52100| Loss : 0.000183 | Y_pred : 0.980868\n",
      "Epoch : 52200| Loss : 0.000183 | Y_pred : 0.980888\n",
      "Epoch : 52300| Loss : 0.000182 | Y_pred : 0.980909\n",
      "Epoch : 52400| Loss : 0.000182 | Y_pred : 0.980929\n",
      "Epoch : 52500| Loss : 0.000181 | Y_pred : 0.980949\n",
      "Epoch : 52600| Loss : 0.000181 | Y_pred : 0.980969\n",
      "Epoch : 52700| Loss : 0.000181 | Y_pred : 0.980989\n",
      "Epoch : 52800| Loss : 0.000180 | Y_pred : 0.981009\n",
      "Epoch : 52900| Loss : 0.000180 | Y_pred : 0.981029\n",
      "Epoch : 53000| Loss : 0.000180 | Y_pred : 0.981049\n",
      "Epoch : 53100| Loss : 0.000179 | Y_pred : 0.981069\n",
      "Epoch : 53200| Loss : 0.000179 | Y_pred : 0.981088\n",
      "Epoch : 53300| Loss : 0.000178 | Y_pred : 0.981108\n",
      "Epoch : 53400| Loss : 0.000178 | Y_pred : 0.981128\n",
      "Epoch : 53500| Loss : 0.000178 | Y_pred : 0.981147\n",
      "Epoch : 53600| Loss : 0.000177 | Y_pred : 0.981167\n",
      "Epoch : 53700| Loss : 0.000177 | Y_pred : 0.981186\n",
      "Epoch : 53800| Loss : 0.000177 | Y_pred : 0.981205\n",
      "Epoch : 53900| Loss : 0.000176 | Y_pred : 0.981225\n",
      "Epoch : 54000| Loss : 0.000176 | Y_pred : 0.981244\n",
      "Epoch : 54100| Loss : 0.000176 | Y_pred : 0.981263\n",
      "Epoch : 54200| Loss : 0.000175 | Y_pred : 0.981282\n",
      "Epoch : 54300| Loss : 0.000175 | Y_pred : 0.981301\n",
      "Epoch : 54400| Loss : 0.000174 | Y_pred : 0.981320\n",
      "Epoch : 54500| Loss : 0.000174 | Y_pred : 0.981339\n",
      "Epoch : 54600| Loss : 0.000174 | Y_pred : 0.981358\n",
      "Epoch : 54700| Loss : 0.000173 | Y_pred : 0.981377\n",
      "Epoch : 54800| Loss : 0.000173 | Y_pred : 0.981396\n",
      "Epoch : 54900| Loss : 0.000173 | Y_pred : 0.981415\n",
      "Epoch : 55000| Loss : 0.000172 | Y_pred : 0.981433\n",
      "Epoch : 55100| Loss : 0.000172 | Y_pred : 0.981452\n",
      "Epoch : 55200| Loss : 0.000172 | Y_pred : 0.981471\n",
      "Epoch : 55300| Loss : 0.000171 | Y_pred : 0.981489\n",
      "Epoch : 55400| Loss : 0.000171 | Y_pred : 0.981508\n",
      "Epoch : 55500| Loss : 0.000171 | Y_pred : 0.981526\n",
      "Epoch : 55600| Loss : 0.000170 | Y_pred : 0.981545\n",
      "Epoch : 55700| Loss : 0.000170 | Y_pred : 0.981563\n",
      "Epoch : 55800| Loss : 0.000170 | Y_pred : 0.981581\n",
      "Epoch : 55900| Loss : 0.000169 | Y_pred : 0.981599\n",
      "Epoch : 56000| Loss : 0.000169 | Y_pred : 0.981618\n",
      "Epoch : 56100| Loss : 0.000169 | Y_pred : 0.981636\n",
      "Epoch : 56200| Loss : 0.000168 | Y_pred : 0.981654\n",
      "Epoch : 56300| Loss : 0.000168 | Y_pred : 0.981672\n",
      "Epoch : 56400| Loss : 0.000168 | Y_pred : 0.981690\n",
      "Epoch : 56500| Loss : 0.000167 | Y_pred : 0.981708\n",
      "Epoch : 56600| Loss : 0.000167 | Y_pred : 0.981726\n",
      "Epoch : 56700| Loss : 0.000167 | Y_pred : 0.981743\n",
      "Epoch : 56800| Loss : 0.000166 | Y_pred : 0.981761\n",
      "Epoch : 56900| Loss : 0.000166 | Y_pred : 0.981779\n",
      "Epoch : 57000| Loss : 0.000166 | Y_pred : 0.981797\n",
      "Epoch : 57100| Loss : 0.000165 | Y_pred : 0.981814\n",
      "Epoch : 57200| Loss : 0.000165 | Y_pred : 0.981832\n",
      "Epoch : 57300| Loss : 0.000165 | Y_pred : 0.981849\n",
      "Epoch : 57400| Loss : 0.000164 | Y_pred : 0.981867\n",
      "Epoch : 57500| Loss : 0.000164 | Y_pred : 0.981884\n",
      "Epoch : 57600| Loss : 0.000164 | Y_pred : 0.981902\n",
      "Epoch : 57700| Loss : 0.000163 | Y_pred : 0.981919\n",
      "Epoch : 57800| Loss : 0.000163 | Y_pred : 0.981936\n",
      "Epoch : 57900| Loss : 0.000163 | Y_pred : 0.981954\n",
      "Epoch : 58000| Loss : 0.000163 | Y_pred : 0.981971\n",
      "Epoch : 58100| Loss : 0.000162 | Y_pred : 0.981988\n",
      "Epoch : 58200| Loss : 0.000162 | Y_pred : 0.982005\n",
      "Epoch : 58300| Loss : 0.000162 | Y_pred : 0.982022\n",
      "Epoch : 58400| Loss : 0.000161 | Y_pred : 0.982039\n",
      "Epoch : 58500| Loss : 0.000161 | Y_pred : 0.982056\n",
      "Epoch : 58600| Loss : 0.000161 | Y_pred : 0.982073\n",
      "Epoch : 58700| Loss : 0.000160 | Y_pred : 0.982090\n",
      "Epoch : 58800| Loss : 0.000160 | Y_pred : 0.982107\n",
      "Epoch : 58900| Loss : 0.000160 | Y_pred : 0.982123\n",
      "Epoch : 59000| Loss : 0.000159 | Y_pred : 0.982140\n",
      "Epoch : 59100| Loss : 0.000159 | Y_pred : 0.982157\n",
      "Epoch : 59200| Loss : 0.000159 | Y_pred : 0.982173\n",
      "Epoch : 59300| Loss : 0.000159 | Y_pred : 0.982190\n",
      "Epoch : 59400| Loss : 0.000158 | Y_pred : 0.982207\n",
      "Epoch : 59500| Loss : 0.000158 | Y_pred : 0.982223\n",
      "Epoch : 59600| Loss : 0.000158 | Y_pred : 0.982240\n",
      "Epoch : 59700| Loss : 0.000157 | Y_pred : 0.982256\n",
      "Epoch : 59800| Loss : 0.000157 | Y_pred : 0.982272\n",
      "Epoch : 59900| Loss : 0.000157 | Y_pred : 0.982289\n",
      "Epoch : 60000| Loss : 0.000157 | Y_pred : 0.982305\n",
      "Epoch : 60100| Loss : 0.000156 | Y_pred : 0.982321\n",
      "Epoch : 60200| Loss : 0.000156 | Y_pred : 0.982338\n",
      "Epoch : 60300| Loss : 0.000156 | Y_pred : 0.982354\n",
      "Epoch : 60400| Loss : 0.000155 | Y_pred : 0.982370\n",
      "Epoch : 60500| Loss : 0.000155 | Y_pred : 0.982386\n",
      "Epoch : 60600| Loss : 0.000155 | Y_pred : 0.982402\n",
      "Epoch : 60700| Loss : 0.000155 | Y_pred : 0.982418\n",
      "Epoch : 60800| Loss : 0.000154 | Y_pred : 0.982434\n",
      "Epoch : 60900| Loss : 0.000154 | Y_pred : 0.982450\n",
      "Epoch : 61000| Loss : 0.000154 | Y_pred : 0.982466\n",
      "Epoch : 61100| Loss : 0.000153 | Y_pred : 0.982482\n",
      "Epoch : 61200| Loss : 0.000153 | Y_pred : 0.982497\n",
      "Epoch : 61300| Loss : 0.000153 | Y_pred : 0.982513\n",
      "Epoch : 61400| Loss : 0.000153 | Y_pred : 0.982529\n",
      "Epoch : 61500| Loss : 0.000152 | Y_pred : 0.982544\n",
      "Epoch : 61600| Loss : 0.000152 | Y_pred : 0.982560\n",
      "Epoch : 61700| Loss : 0.000152 | Y_pred : 0.982576\n",
      "Epoch : 61800| Loss : 0.000152 | Y_pred : 0.982591\n",
      "Epoch : 61900| Loss : 0.000151 | Y_pred : 0.982607\n",
      "Epoch : 62000| Loss : 0.000151 | Y_pred : 0.982622\n",
      "Epoch : 62100| Loss : 0.000151 | Y_pred : 0.982638\n",
      "Epoch : 62200| Loss : 0.000150 | Y_pred : 0.982653\n",
      "Epoch : 62300| Loss : 0.000150 | Y_pred : 0.982668\n",
      "Epoch : 62400| Loss : 0.000150 | Y_pred : 0.982684\n",
      "Epoch : 62500| Loss : 0.000150 | Y_pred : 0.982699\n",
      "Epoch : 62600| Loss : 0.000149 | Y_pred : 0.982714\n",
      "Epoch : 62700| Loss : 0.000149 | Y_pred : 0.982729\n",
      "Epoch : 62800| Loss : 0.000149 | Y_pred : 0.982745\n",
      "Epoch : 62900| Loss : 0.000149 | Y_pred : 0.982760\n",
      "Epoch : 63000| Loss : 0.000148 | Y_pred : 0.982775\n",
      "Epoch : 63100| Loss : 0.000148 | Y_pred : 0.982790\n",
      "Epoch : 63200| Loss : 0.000148 | Y_pred : 0.982805\n",
      "Epoch : 63300| Loss : 0.000148 | Y_pred : 0.982820\n",
      "Epoch : 63400| Loss : 0.000147 | Y_pred : 0.982835\n",
      "Epoch : 63500| Loss : 0.000147 | Y_pred : 0.982850\n",
      "Epoch : 63600| Loss : 0.000147 | Y_pred : 0.982864\n",
      "Epoch : 63700| Loss : 0.000147 | Y_pred : 0.982879\n",
      "Epoch : 63800| Loss : 0.000146 | Y_pred : 0.982894\n",
      "Epoch : 63900| Loss : 0.000146 | Y_pred : 0.982909\n",
      "Epoch : 64000| Loss : 0.000146 | Y_pred : 0.982924\n",
      "Epoch : 64100| Loss : 0.000146 | Y_pred : 0.982938\n",
      "Epoch : 64200| Loss : 0.000145 | Y_pred : 0.982953\n",
      "Epoch : 64300| Loss : 0.000145 | Y_pred : 0.982967\n",
      "Epoch : 64400| Loss : 0.000145 | Y_pred : 0.982982\n",
      "Epoch : 64500| Loss : 0.000145 | Y_pred : 0.982997\n",
      "Epoch : 64600| Loss : 0.000144 | Y_pred : 0.983011\n",
      "Epoch : 64700| Loss : 0.000144 | Y_pred : 0.983026\n",
      "Epoch : 64800| Loss : 0.000144 | Y_pred : 0.983040\n",
      "Epoch : 64900| Loss : 0.000144 | Y_pred : 0.983054\n",
      "Epoch : 65000| Loss : 0.000143 | Y_pred : 0.983069\n",
      "Epoch : 65100| Loss : 0.000143 | Y_pred : 0.983083\n",
      "Epoch : 65200| Loss : 0.000143 | Y_pred : 0.983097\n",
      "Epoch : 65300| Loss : 0.000143 | Y_pred : 0.983112\n",
      "Epoch : 65400| Loss : 0.000142 | Y_pred : 0.983126\n",
      "Epoch : 65500| Loss : 0.000142 | Y_pred : 0.983140\n",
      "Epoch : 65600| Loss : 0.000142 | Y_pred : 0.983154\n",
      "Epoch : 65700| Loss : 0.000142 | Y_pred : 0.983168\n",
      "Epoch : 65800| Loss : 0.000141 | Y_pred : 0.983182\n",
      "Epoch : 65900| Loss : 0.000141 | Y_pred : 0.983196\n",
      "Epoch : 66000| Loss : 0.000141 | Y_pred : 0.983210\n",
      "Epoch : 66100| Loss : 0.000141 | Y_pred : 0.983224\n",
      "Epoch : 66200| Loss : 0.000140 | Y_pred : 0.983238\n",
      "Epoch : 66300| Loss : 0.000140 | Y_pred : 0.983252\n",
      "Epoch : 66400| Loss : 0.000140 | Y_pred : 0.983266\n",
      "Epoch : 66500| Loss : 0.000140 | Y_pred : 0.983280\n",
      "Epoch : 66600| Loss : 0.000140 | Y_pred : 0.983294\n",
      "Epoch : 66700| Loss : 0.000139 | Y_pred : 0.983308\n",
      "Epoch : 66800| Loss : 0.000139 | Y_pred : 0.983321\n",
      "Epoch : 66900| Loss : 0.000139 | Y_pred : 0.983335\n",
      "Epoch : 67000| Loss : 0.000139 | Y_pred : 0.983349\n",
      "Epoch : 67100| Loss : 0.000138 | Y_pred : 0.983362\n",
      "Epoch : 67200| Loss : 0.000138 | Y_pred : 0.983376\n",
      "Epoch : 67300| Loss : 0.000138 | Y_pred : 0.983390\n",
      "Epoch : 67400| Loss : 0.000138 | Y_pred : 0.983403\n",
      "Epoch : 67500| Loss : 0.000138 | Y_pred : 0.983417\n",
      "Epoch : 67600| Loss : 0.000137 | Y_pred : 0.983430\n",
      "Epoch : 67700| Loss : 0.000137 | Y_pred : 0.983444\n",
      "Epoch : 67800| Loss : 0.000137 | Y_pred : 0.983457\n",
      "Epoch : 67900| Loss : 0.000137 | Y_pred : 0.983470\n",
      "Epoch : 68000| Loss : 0.000136 | Y_pred : 0.983484\n",
      "Epoch : 68100| Loss : 0.000136 | Y_pred : 0.983497\n",
      "Epoch : 68200| Loss : 0.000136 | Y_pred : 0.983510\n",
      "Epoch : 68300| Loss : 0.000136 | Y_pred : 0.983524\n",
      "Epoch : 68400| Loss : 0.000136 | Y_pred : 0.983537\n",
      "Epoch : 68500| Loss : 0.000135 | Y_pred : 0.983550\n",
      "Epoch : 68600| Loss : 0.000135 | Y_pred : 0.983563\n",
      "Epoch : 68700| Loss : 0.000135 | Y_pred : 0.983577\n",
      "Epoch : 68800| Loss : 0.000135 | Y_pred : 0.983590\n",
      "Epoch : 68900| Loss : 0.000134 | Y_pred : 0.983603\n",
      "Epoch : 69000| Loss : 0.000134 | Y_pred : 0.983616\n",
      "Epoch : 69100| Loss : 0.000134 | Y_pred : 0.983629\n",
      "Epoch : 69200| Loss : 0.000134 | Y_pred : 0.983642\n",
      "Epoch : 69300| Loss : 0.000134 | Y_pred : 0.983655\n",
      "Epoch : 69400| Loss : 0.000133 | Y_pred : 0.983668\n",
      "Epoch : 69500| Loss : 0.000133 | Y_pred : 0.983681\n",
      "Epoch : 69600| Loss : 0.000133 | Y_pred : 0.983694\n",
      "Epoch : 69700| Loss : 0.000133 | Y_pred : 0.983706\n",
      "Epoch : 69800| Loss : 0.000133 | Y_pred : 0.983719\n",
      "Epoch : 69900| Loss : 0.000132 | Y_pred : 0.983732\n",
      "Epoch : 70000| Loss : 0.000132 | Y_pred : 0.983745\n",
      "Epoch : 70100| Loss : 0.000132 | Y_pred : 0.983758\n",
      "Epoch : 70200| Loss : 0.000132 | Y_pred : 0.983770\n",
      "Epoch : 70300| Loss : 0.000131 | Y_pred : 0.983783\n",
      "Epoch : 70400| Loss : 0.000131 | Y_pred : 0.983796\n",
      "Epoch : 70500| Loss : 0.000131 | Y_pred : 0.983808\n",
      "Epoch : 70600| Loss : 0.000131 | Y_pred : 0.983821\n",
      "Epoch : 70700| Loss : 0.000131 | Y_pred : 0.983833\n",
      "Epoch : 70800| Loss : 0.000130 | Y_pred : 0.983846\n",
      "Epoch : 70900| Loss : 0.000130 | Y_pred : 0.983858\n",
      "Epoch : 71000| Loss : 0.000130 | Y_pred : 0.983871\n",
      "Epoch : 71100| Loss : 0.000130 | Y_pred : 0.983883\n",
      "Epoch : 71200| Loss : 0.000130 | Y_pred : 0.983896\n",
      "Epoch : 71300| Loss : 0.000129 | Y_pred : 0.983908\n",
      "Epoch : 71400| Loss : 0.000129 | Y_pred : 0.983921\n",
      "Epoch : 71500| Loss : 0.000129 | Y_pred : 0.983933\n",
      "Epoch : 71600| Loss : 0.000129 | Y_pred : 0.983945\n",
      "Epoch : 71700| Loss : 0.000129 | Y_pred : 0.983958\n",
      "Epoch : 71800| Loss : 0.000128 | Y_pred : 0.983970\n",
      "Epoch : 71900| Loss : 0.000128 | Y_pred : 0.983982\n",
      "Epoch : 72000| Loss : 0.000128 | Y_pred : 0.983994\n",
      "Epoch : 72100| Loss : 0.000128 | Y_pred : 0.984006\n",
      "Epoch : 72200| Loss : 0.000128 | Y_pred : 0.984019\n",
      "Epoch : 72300| Loss : 0.000128 | Y_pred : 0.984031\n",
      "Epoch : 72400| Loss : 0.000127 | Y_pred : 0.984043\n",
      "Epoch : 72500| Loss : 0.000127 | Y_pred : 0.984055\n",
      "Epoch : 72600| Loss : 0.000127 | Y_pred : 0.984067\n",
      "Epoch : 72700| Loss : 0.000127 | Y_pred : 0.984079\n",
      "Epoch : 72800| Loss : 0.000127 | Y_pred : 0.984091\n",
      "Epoch : 72900| Loss : 0.000126 | Y_pred : 0.984103\n",
      "Epoch : 73000| Loss : 0.000126 | Y_pred : 0.984115\n",
      "Epoch : 73100| Loss : 0.000126 | Y_pred : 0.984127\n",
      "Epoch : 73200| Loss : 0.000126 | Y_pred : 0.984139\n",
      "Epoch : 73300| Loss : 0.000126 | Y_pred : 0.984151\n",
      "Epoch : 73400| Loss : 0.000125 | Y_pred : 0.984163\n",
      "Epoch : 73500| Loss : 0.000125 | Y_pred : 0.984174\n",
      "Epoch : 73600| Loss : 0.000125 | Y_pred : 0.984186\n",
      "Epoch : 73700| Loss : 0.000125 | Y_pred : 0.984198\n",
      "Epoch : 73800| Loss : 0.000125 | Y_pred : 0.984210\n",
      "Epoch : 73900| Loss : 0.000124 | Y_pred : 0.984221\n",
      "Epoch : 74000| Loss : 0.000124 | Y_pred : 0.984233\n",
      "Epoch : 74100| Loss : 0.000124 | Y_pred : 0.984245\n",
      "Epoch : 74200| Loss : 0.000124 | Y_pred : 0.984256\n",
      "Epoch : 74300| Loss : 0.000124 | Y_pred : 0.984268\n",
      "Epoch : 74400| Loss : 0.000124 | Y_pred : 0.984280\n",
      "Epoch : 74500| Loss : 0.000123 | Y_pred : 0.984291\n",
      "Epoch : 74600| Loss : 0.000123 | Y_pred : 0.984303\n",
      "Epoch : 74700| Loss : 0.000123 | Y_pred : 0.984314\n",
      "Epoch : 74800| Loss : 0.000123 | Y_pred : 0.984326\n",
      "Epoch : 74900| Loss : 0.000123 | Y_pred : 0.984337\n",
      "Epoch : 75000| Loss : 0.000122 | Y_pred : 0.984349\n",
      "Epoch : 75100| Loss : 0.000122 | Y_pred : 0.984360\n",
      "Epoch : 75200| Loss : 0.000122 | Y_pred : 0.984372\n",
      "Epoch : 75300| Loss : 0.000122 | Y_pred : 0.984383\n",
      "Epoch : 75400| Loss : 0.000122 | Y_pred : 0.984394\n",
      "Epoch : 75500| Loss : 0.000122 | Y_pred : 0.984406\n",
      "Epoch : 75600| Loss : 0.000121 | Y_pred : 0.984417\n",
      "Epoch : 75700| Loss : 0.000121 | Y_pred : 0.984428\n",
      "Epoch : 75800| Loss : 0.000121 | Y_pred : 0.984439\n",
      "Epoch : 75900| Loss : 0.000121 | Y_pred : 0.984451\n",
      "Epoch : 76000| Loss : 0.000121 | Y_pred : 0.984462\n",
      "Epoch : 76100| Loss : 0.000121 | Y_pred : 0.984473\n",
      "Epoch : 76200| Loss : 0.000120 | Y_pred : 0.984484\n",
      "Epoch : 76300| Loss : 0.000120 | Y_pred : 0.984495\n",
      "Epoch : 76400| Loss : 0.000120 | Y_pred : 0.984507\n",
      "Epoch : 76500| Loss : 0.000120 | Y_pred : 0.984518\n",
      "Epoch : 76600| Loss : 0.000120 | Y_pred : 0.984529\n",
      "Epoch : 76700| Loss : 0.000120 | Y_pred : 0.984540\n",
      "Epoch : 76800| Loss : 0.000119 | Y_pred : 0.984551\n",
      "Epoch : 76900| Loss : 0.000119 | Y_pred : 0.984562\n",
      "Epoch : 77000| Loss : 0.000119 | Y_pred : 0.984573\n",
      "Epoch : 77100| Loss : 0.000119 | Y_pred : 0.984584\n",
      "Epoch : 77200| Loss : 0.000119 | Y_pred : 0.984595\n",
      "Epoch : 77300| Loss : 0.000118 | Y_pred : 0.984606\n",
      "Epoch : 77400| Loss : 0.000118 | Y_pred : 0.984617\n",
      "Epoch : 77500| Loss : 0.000118 | Y_pred : 0.984627\n",
      "Epoch : 77600| Loss : 0.000118 | Y_pred : 0.984638\n",
      "Epoch : 77700| Loss : 0.000118 | Y_pred : 0.984649\n",
      "Epoch : 77800| Loss : 0.000118 | Y_pred : 0.984660\n",
      "Epoch : 77900| Loss : 0.000117 | Y_pred : 0.984671\n",
      "Epoch : 78000| Loss : 0.000117 | Y_pred : 0.984681\n",
      "Epoch : 78100| Loss : 0.000117 | Y_pred : 0.984692\n",
      "Epoch : 78200| Loss : 0.000117 | Y_pred : 0.984703\n",
      "Epoch : 78300| Loss : 0.000117 | Y_pred : 0.984714\n",
      "Epoch : 78400| Loss : 0.000117 | Y_pred : 0.984724\n",
      "Epoch : 78500| Loss : 0.000117 | Y_pred : 0.984735\n",
      "Epoch : 78600| Loss : 0.000116 | Y_pred : 0.984746\n",
      "Epoch : 78700| Loss : 0.000116 | Y_pred : 0.984756\n",
      "Epoch : 78800| Loss : 0.000116 | Y_pred : 0.984767\n",
      "Epoch : 78900| Loss : 0.000116 | Y_pred : 0.984777\n",
      "Epoch : 79000| Loss : 0.000116 | Y_pred : 0.984788\n",
      "Epoch : 79100| Loss : 0.000116 | Y_pred : 0.984798\n",
      "Epoch : 79200| Loss : 0.000115 | Y_pred : 0.984809\n",
      "Epoch : 79300| Loss : 0.000115 | Y_pred : 0.984819\n",
      "Epoch : 79400| Loss : 0.000115 | Y_pred : 0.984830\n",
      "Epoch : 79500| Loss : 0.000115 | Y_pred : 0.984840\n",
      "Epoch : 79600| Loss : 0.000115 | Y_pred : 0.984851\n",
      "Epoch : 79700| Loss : 0.000115 | Y_pred : 0.984861\n",
      "Epoch : 79800| Loss : 0.000114 | Y_pred : 0.984872\n",
      "Epoch : 79900| Loss : 0.000114 | Y_pred : 0.984882\n",
      "Epoch : 80000| Loss : 0.000114 | Y_pred : 0.984892\n",
      "Epoch : 80100| Loss : 0.000114 | Y_pred : 0.984903\n",
      "Epoch : 80200| Loss : 0.000114 | Y_pred : 0.984913\n",
      "Epoch : 80300| Loss : 0.000114 | Y_pred : 0.984923\n",
      "Epoch : 80400| Loss : 0.000114 | Y_pred : 0.984933\n",
      "Epoch : 80500| Loss : 0.000113 | Y_pred : 0.984944\n",
      "Epoch : 80600| Loss : 0.000113 | Y_pred : 0.984954\n",
      "Epoch : 80700| Loss : 0.000113 | Y_pred : 0.984964\n",
      "Epoch : 80800| Loss : 0.000113 | Y_pred : 0.984974\n",
      "Epoch : 80900| Loss : 0.000113 | Y_pred : 0.984984\n",
      "Epoch : 81000| Loss : 0.000113 | Y_pred : 0.984995\n",
      "Epoch : 81100| Loss : 0.000112 | Y_pred : 0.985005\n",
      "Epoch : 81200| Loss : 0.000112 | Y_pred : 0.985015\n",
      "Epoch : 81300| Loss : 0.000112 | Y_pred : 0.985025\n",
      "Epoch : 81400| Loss : 0.000112 | Y_pred : 0.985035\n",
      "Epoch : 81500| Loss : 0.000112 | Y_pred : 0.985045\n",
      "Epoch : 81600| Loss : 0.000112 | Y_pred : 0.985055\n",
      "Epoch : 81700| Loss : 0.000112 | Y_pred : 0.985065\n",
      "Epoch : 81800| Loss : 0.000111 | Y_pred : 0.985075\n",
      "Epoch : 81900| Loss : 0.000111 | Y_pred : 0.985085\n",
      "Epoch : 82000| Loss : 0.000111 | Y_pred : 0.985095\n",
      "Epoch : 82100| Loss : 0.000111 | Y_pred : 0.985105\n",
      "Epoch : 82200| Loss : 0.000111 | Y_pred : 0.985115\n",
      "Epoch : 82300| Loss : 0.000111 | Y_pred : 0.985125\n",
      "Epoch : 82400| Loss : 0.000110 | Y_pred : 0.985135\n",
      "Epoch : 82500| Loss : 0.000110 | Y_pred : 0.985144\n",
      "Epoch : 82600| Loss : 0.000110 | Y_pred : 0.985154\n",
      "Epoch : 82700| Loss : 0.000110 | Y_pred : 0.985164\n",
      "Epoch : 82800| Loss : 0.000110 | Y_pred : 0.985174\n",
      "Epoch : 82900| Loss : 0.000110 | Y_pred : 0.985184\n",
      "Epoch : 83000| Loss : 0.000110 | Y_pred : 0.985193\n",
      "Epoch : 83100| Loss : 0.000109 | Y_pred : 0.985203\n",
      "Epoch : 83200| Loss : 0.000109 | Y_pred : 0.985213\n",
      "Epoch : 83300| Loss : 0.000109 | Y_pred : 0.985223\n",
      "Epoch : 83400| Loss : 0.000109 | Y_pred : 0.985232\n",
      "Epoch : 83500| Loss : 0.000109 | Y_pred : 0.985242\n",
      "Epoch : 83600| Loss : 0.000109 | Y_pred : 0.985252\n",
      "Epoch : 83700| Loss : 0.000109 | Y_pred : 0.985261\n",
      "Epoch : 83800| Loss : 0.000108 | Y_pred : 0.985271\n",
      "Epoch : 83900| Loss : 0.000108 | Y_pred : 0.985280\n",
      "Epoch : 84000| Loss : 0.000108 | Y_pred : 0.985290\n",
      "Epoch : 84100| Loss : 0.000108 | Y_pred : 0.985300\n",
      "Epoch : 84200| Loss : 0.000108 | Y_pred : 0.985309\n",
      "Epoch : 84300| Loss : 0.000108 | Y_pred : 0.985319\n",
      "Epoch : 84400| Loss : 0.000108 | Y_pred : 0.985328\n",
      "Epoch : 84500| Loss : 0.000107 | Y_pred : 0.985338\n",
      "Epoch : 84600| Loss : 0.000107 | Y_pred : 0.985347\n",
      "Epoch : 84700| Loss : 0.000107 | Y_pred : 0.985357\n",
      "Epoch : 84800| Loss : 0.000107 | Y_pred : 0.985366\n",
      "Epoch : 84900| Loss : 0.000107 | Y_pred : 0.985375\n",
      "Epoch : 85000| Loss : 0.000107 | Y_pred : 0.985385\n",
      "Epoch : 85100| Loss : 0.000107 | Y_pred : 0.985394\n",
      "Epoch : 85200| Loss : 0.000107 | Y_pred : 0.985404\n",
      "Epoch : 85300| Loss : 0.000106 | Y_pred : 0.985413\n",
      "Epoch : 85400| Loss : 0.000106 | Y_pred : 0.985422\n",
      "Epoch : 85500| Loss : 0.000106 | Y_pred : 0.985432\n",
      "Epoch : 85600| Loss : 0.000106 | Y_pred : 0.985441\n",
      "Epoch : 85700| Loss : 0.000106 | Y_pred : 0.985450\n",
      "Epoch : 85800| Loss : 0.000106 | Y_pred : 0.985459\n",
      "Epoch : 85900| Loss : 0.000106 | Y_pred : 0.985469\n",
      "Epoch : 86000| Loss : 0.000105 | Y_pred : 0.985478\n",
      "Epoch : 86100| Loss : 0.000105 | Y_pred : 0.985487\n",
      "Epoch : 86200| Loss : 0.000105 | Y_pred : 0.985496\n",
      "Epoch : 86300| Loss : 0.000105 | Y_pred : 0.985505\n",
      "Epoch : 86400| Loss : 0.000105 | Y_pred : 0.985515\n",
      "Epoch : 86500| Loss : 0.000105 | Y_pred : 0.985524\n",
      "Epoch : 86600| Loss : 0.000105 | Y_pred : 0.985533\n",
      "Epoch : 86700| Loss : 0.000105 | Y_pred : 0.985542\n",
      "Epoch : 86800| Loss : 0.000104 | Y_pred : 0.985551\n",
      "Epoch : 86900| Loss : 0.000104 | Y_pred : 0.985560\n",
      "Epoch : 87000| Loss : 0.000104 | Y_pred : 0.985569\n",
      "Epoch : 87100| Loss : 0.000104 | Y_pred : 0.985578\n",
      "Epoch : 87200| Loss : 0.000104 | Y_pred : 0.985587\n",
      "Epoch : 87300| Loss : 0.000104 | Y_pred : 0.985596\n",
      "Epoch : 87400| Loss : 0.000104 | Y_pred : 0.985605\n",
      "Epoch : 87500| Loss : 0.000103 | Y_pred : 0.985614\n",
      "Epoch : 87600| Loss : 0.000103 | Y_pred : 0.985623\n",
      "Epoch : 87700| Loss : 0.000103 | Y_pred : 0.985632\n",
      "Epoch : 87800| Loss : 0.000103 | Y_pred : 0.985641\n",
      "Epoch : 87900| Loss : 0.000103 | Y_pred : 0.985650\n",
      "Epoch : 88000| Loss : 0.000103 | Y_pred : 0.985659\n",
      "Epoch : 88100| Loss : 0.000103 | Y_pred : 0.985668\n",
      "Epoch : 88200| Loss : 0.000103 | Y_pred : 0.985677\n",
      "Epoch : 88300| Loss : 0.000102 | Y_pred : 0.985686\n",
      "Epoch : 88400| Loss : 0.000102 | Y_pred : 0.985694\n",
      "Epoch : 88500| Loss : 0.000102 | Y_pred : 0.985703\n",
      "Epoch : 88600| Loss : 0.000102 | Y_pred : 0.985712\n",
      "Epoch : 88700| Loss : 0.000102 | Y_pred : 0.985721\n",
      "Epoch : 88800| Loss : 0.000102 | Y_pred : 0.985730\n",
      "Epoch : 88900| Loss : 0.000102 | Y_pred : 0.985738\n",
      "Epoch : 89000| Loss : 0.000102 | Y_pred : 0.985747\n",
      "Epoch : 89100| Loss : 0.000101 | Y_pred : 0.985756\n",
      "Epoch : 89200| Loss : 0.000101 | Y_pred : 0.985765\n",
      "Epoch : 89300| Loss : 0.000101 | Y_pred : 0.985773\n",
      "Epoch : 89400| Loss : 0.000101 | Y_pred : 0.985782\n",
      "Epoch : 89500| Loss : 0.000101 | Y_pred : 0.985791\n",
      "Epoch : 89600| Loss : 0.000101 | Y_pred : 0.985799\n",
      "Epoch : 89700| Loss : 0.000101 | Y_pred : 0.985808\n",
      "Epoch : 89800| Loss : 0.000101 | Y_pred : 0.985817\n",
      "Epoch : 89900| Loss : 0.000100 | Y_pred : 0.985825\n",
      "Epoch : 90000| Loss : 0.000100 | Y_pred : 0.985834\n",
      "Epoch : 90100| Loss : 0.000100 | Y_pred : 0.985842\n",
      "Epoch : 90200| Loss : 0.000100 | Y_pred : 0.985851\n",
      "Epoch : 90300| Loss : 0.000100 | Y_pred : 0.985859\n",
      "Epoch : 90400| Loss : 0.000100 | Y_pred : 0.985868\n",
      "Epoch : 90500| Loss : 0.000100 | Y_pred : 0.985877\n",
      "Epoch : 90600| Loss : 0.000100 | Y_pred : 0.985885\n",
      "Epoch : 90700| Loss : 0.000099 | Y_pred : 0.985894\n",
      "Epoch : 90800| Loss : 0.000099 | Y_pred : 0.985902\n",
      "Epoch : 90900| Loss : 0.000099 | Y_pred : 0.985910\n",
      "Epoch : 91000| Loss : 0.000099 | Y_pred : 0.985919\n",
      "Epoch : 91100| Loss : 0.000099 | Y_pred : 0.985927\n",
      "Epoch : 91200| Loss : 0.000099 | Y_pred : 0.985936\n",
      "Epoch : 91300| Loss : 0.000099 | Y_pred : 0.985944\n",
      "Epoch : 91400| Loss : 0.000099 | Y_pred : 0.985953\n",
      "Epoch : 91500| Loss : 0.000099 | Y_pred : 0.985961\n",
      "Epoch : 91600| Loss : 0.000098 | Y_pred : 0.985969\n",
      "Epoch : 91700| Loss : 0.000098 | Y_pred : 0.985978\n",
      "Epoch : 91800| Loss : 0.000098 | Y_pred : 0.985986\n",
      "Epoch : 91900| Loss : 0.000098 | Y_pred : 0.985994\n",
      "Epoch : 92000| Loss : 0.000098 | Y_pred : 0.986003\n",
      "Epoch : 92100| Loss : 0.000098 | Y_pred : 0.986011\n",
      "Epoch : 92200| Loss : 0.000098 | Y_pred : 0.986019\n",
      "Epoch : 92300| Loss : 0.000098 | Y_pred : 0.986027\n",
      "Epoch : 92400| Loss : 0.000098 | Y_pred : 0.986036\n",
      "Epoch : 92500| Loss : 0.000097 | Y_pred : 0.986044\n",
      "Epoch : 92600| Loss : 0.000097 | Y_pred : 0.986052\n",
      "Epoch : 92700| Loss : 0.000097 | Y_pred : 0.986060\n",
      "Epoch : 92800| Loss : 0.000097 | Y_pred : 0.986068\n",
      "Epoch : 92900| Loss : 0.000097 | Y_pred : 0.986077\n",
      "Epoch : 93000| Loss : 0.000097 | Y_pred : 0.986085\n",
      "Epoch : 93100| Loss : 0.000097 | Y_pred : 0.986093\n",
      "Epoch : 93200| Loss : 0.000097 | Y_pred : 0.986101\n",
      "Epoch : 93300| Loss : 0.000096 | Y_pred : 0.986109\n",
      "Epoch : 93400| Loss : 0.000096 | Y_pred : 0.986117\n",
      "Epoch : 93500| Loss : 0.000096 | Y_pred : 0.986125\n",
      "Epoch : 93600| Loss : 0.000096 | Y_pred : 0.986134\n",
      "Epoch : 93700| Loss : 0.000096 | Y_pred : 0.986142\n",
      "Epoch : 93800| Loss : 0.000096 | Y_pred : 0.986150\n",
      "Epoch : 93900| Loss : 0.000096 | Y_pred : 0.986158\n",
      "Epoch : 94000| Loss : 0.000096 | Y_pred : 0.986166\n",
      "Epoch : 94100| Loss : 0.000096 | Y_pred : 0.986174\n",
      "Epoch : 94200| Loss : 0.000095 | Y_pred : 0.986182\n",
      "Epoch : 94300| Loss : 0.000095 | Y_pred : 0.986190\n",
      "Epoch : 94400| Loss : 0.000095 | Y_pred : 0.986198\n",
      "Epoch : 94500| Loss : 0.000095 | Y_pred : 0.986206\n",
      "Epoch : 94600| Loss : 0.000095 | Y_pred : 0.986214\n",
      "Epoch : 94700| Loss : 0.000095 | Y_pred : 0.986221\n",
      "Epoch : 94800| Loss : 0.000095 | Y_pred : 0.986229\n",
      "Epoch : 94900| Loss : 0.000095 | Y_pred : 0.986237\n",
      "Epoch : 95000| Loss : 0.000095 | Y_pred : 0.986245\n",
      "Epoch : 95100| Loss : 0.000094 | Y_pred : 0.986253\n",
      "Epoch : 95200| Loss : 0.000094 | Y_pred : 0.986261\n",
      "Epoch : 95300| Loss : 0.000094 | Y_pred : 0.986269\n",
      "Epoch : 95400| Loss : 0.000094 | Y_pred : 0.986277\n",
      "Epoch : 95500| Loss : 0.000094 | Y_pred : 0.986284\n",
      "Epoch : 95600| Loss : 0.000094 | Y_pred : 0.986292\n",
      "Epoch : 95700| Loss : 0.000094 | Y_pred : 0.986300\n",
      "Epoch : 95800| Loss : 0.000094 | Y_pred : 0.986308\n",
      "Epoch : 95900| Loss : 0.000094 | Y_pred : 0.986316\n",
      "Epoch : 96000| Loss : 0.000094 | Y_pred : 0.986323\n",
      "Epoch : 96100| Loss : 0.000093 | Y_pred : 0.986331\n",
      "Epoch : 96200| Loss : 0.000093 | Y_pred : 0.986339\n",
      "Epoch : 96300| Loss : 0.000093 | Y_pred : 0.986347\n",
      "Epoch : 96400| Loss : 0.000093 | Y_pred : 0.986354\n",
      "Epoch : 96500| Loss : 0.000093 | Y_pred : 0.986362\n",
      "Epoch : 96600| Loss : 0.000093 | Y_pred : 0.986370\n",
      "Epoch : 96700| Loss : 0.000093 | Y_pred : 0.986377\n",
      "Epoch : 96800| Loss : 0.000093 | Y_pred : 0.986385\n",
      "Epoch : 96900| Loss : 0.000093 | Y_pred : 0.986393\n",
      "Epoch : 97000| Loss : 0.000092 | Y_pred : 0.986400\n",
      "Epoch : 97100| Loss : 0.000092 | Y_pred : 0.986408\n",
      "Epoch : 97200| Loss : 0.000092 | Y_pred : 0.986416\n",
      "Epoch : 97300| Loss : 0.000092 | Y_pred : 0.986423\n",
      "Epoch : 97400| Loss : 0.000092 | Y_pred : 0.986431\n",
      "Epoch : 97500| Loss : 0.000092 | Y_pred : 0.986438\n",
      "Epoch : 97600| Loss : 0.000092 | Y_pred : 0.986446\n",
      "Epoch : 97700| Loss : 0.000092 | Y_pred : 0.986454\n",
      "Epoch : 97800| Loss : 0.000092 | Y_pred : 0.986461\n",
      "Epoch : 97900| Loss : 0.000092 | Y_pred : 0.986469\n",
      "Epoch : 98000| Loss : 0.000091 | Y_pred : 0.986476\n",
      "Epoch : 98100| Loss : 0.000091 | Y_pred : 0.986484\n",
      "Epoch : 98200| Loss : 0.000091 | Y_pred : 0.986491\n",
      "Epoch : 98300| Loss : 0.000091 | Y_pred : 0.986499\n",
      "Epoch : 98400| Loss : 0.000091 | Y_pred : 0.986506\n",
      "Epoch : 98500| Loss : 0.000091 | Y_pred : 0.986514\n",
      "Epoch : 98600| Loss : 0.000091 | Y_pred : 0.986521\n",
      "Epoch : 98700| Loss : 0.000091 | Y_pred : 0.986528\n",
      "Epoch : 98800| Loss : 0.000091 | Y_pred : 0.986536\n",
      "Epoch : 98900| Loss : 0.000091 | Y_pred : 0.986543\n",
      "Epoch : 99000| Loss : 0.000090 | Y_pred : 0.986551\n",
      "Epoch : 99100| Loss : 0.000090 | Y_pred : 0.986558\n",
      "Epoch : 99200| Loss : 0.000090 | Y_pred : 0.986565\n",
      "Epoch : 99300| Loss : 0.000090 | Y_pred : 0.986573\n",
      "Epoch : 99400| Loss : 0.000090 | Y_pred : 0.986580\n",
      "Epoch : 99500| Loss : 0.000090 | Y_pred : 0.986587\n",
      "Epoch : 99600| Loss : 0.000090 | Y_pred : 0.986595\n",
      "Epoch : 99700| Loss : 0.000090 | Y_pred : 0.986602\n",
      "Epoch : 99800| Loss : 0.000090 | Y_pred : 0.986609\n",
      "Epoch : 99900| Loss : 0.000090 | Y_pred : 0.986617\n",
      "Epoch : 100000| Loss : 0.000089 | Y_pred : 0.986624\n"
     ]
    }
   ],
   "source": [
    "LR=0.01\n",
    "epochs=100000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # ============================== FORWARD PASS ===================================================\n",
    "    # Input Layer -> Hidden Layer 1\n",
    "    z_input_hidden1 = X@w_input_hidden1+b_input_hidden1  # (1,16)\n",
    "    a_input_hidden1 = Sigmoid_Activation(z_input_hidden1)  # (1,16)\n",
    "\n",
    "    # Hidden Layer 1 -> Hidden Layer 2\n",
    "    z_hidden1_hidden2 = a_input_hidden1@w_hidden1_hidden2 + \\\n",
    "        b_hidden1_hidden2  # (1,8)\n",
    "    a_hidden1_hidden2 = Sigmoid_Activation(z_hidden1_hidden2)  # (1,8)\n",
    "\n",
    "\n",
    "    # Hidden Layer 2 -> Hidden Layer 3\n",
    "    z_hidden2_hidden3 = a_hidden1_hidden2@w_hidden2_hidden3+b_hidden2_hidden3\n",
    "    a_hidden2_hidden3 = Sigmoid_Activation(z_hidden2_hidden3)  # (1,4)\n",
    "\n",
    "\n",
    "    # Hidden Layer 3 -> Output Layer\n",
    "    z_hidden3_output = a_hidden2_hidden3@w_hidden3_output+b_hidden3_output\n",
    "    Y_pred = Sigmoid_Activation(z_hidden3_output)  # (1,1)\n",
    "\n",
    "\n",
    "    # LOSS FUNCTION\n",
    "    L=0.5*(Y_pred - Y_true)**2\n",
    "\n",
    "    # ====================================== BACKPROPAGATION =============================================\n",
    "    # Output Layer -> Hidden Layer 3\n",
    "    # ====================================== WEIGHTS GRADIENTS ===========================================\n",
    "    # dL/dw_hidden3_output = dL/dY_pred * dY_pred/dz_hidden3_output * dz_hidden3_output/dw_hidden3_output\n",
    "\n",
    "    dL_dY_pred = (Y_pred - Y_true) # (1,1)\n",
    "    dY_pred_dz_hidden3_output = Y_pred * (1-Y_pred) # (1,1)\n",
    "    dz_hidden3_output_dw_hidden3_output = a_hidden2_hidden3 # (1,4)\n",
    "\n",
    "    # dL/dz_hidden3_output = dL/dY_pred * dY_pred/dz_hidden3_output\n",
    "    dL_dz_hidden3_output = dL_dY_pred * dY_pred_dz_hidden3_output # (1,1)\n",
    "\n",
    "    # dL/dw_hidden3_output = dL/dz_hidden3_output * dz_hidden3_output/dw_hidden3_output\n",
    "    dL_dw_hidden3_output = dz_hidden3_output_dw_hidden3_output.T @ dL_dz_hidden3_output # (4,1)\n",
    "\n",
    "\n",
    "    # ================================ BIAS GRADIENTS ==============================================\n",
    "    # dL/db_hidden3_output = dL/dY_pred * dY_pred/dz_hidden3_output * dz_hidden3_output/db_hidden3_output\n",
    "    # dL/dz_hidden3_output = dL/dY_pred * dY_pred/dz_hidden3_output\n",
    "    # dL/db_hidden3_output = dL/dz_hidden3_output * dz_hidden3_output/db_hidden3_output\n",
    "\n",
    "    dL_dz_hidden3_output = dL_dY_pred * dY_pred_dz_hidden3_output  # (1,1)\n",
    "    dz_hidden3_output_db_hidden3_output = 1\n",
    "\n",
    "    # dL/db_hidden3_output = dL/dz_hidden3_output * dz_hidden3_output/db_hidden3_output\n",
    "    dL_db_hidden3_output = dL_dz_hidden3_output * dz_hidden3_output_db_hidden3_output # (1,1)\n",
    "\n",
    "\n",
    "\n",
    "    # Hidden Layer 3 -> Hidden layer 2\n",
    "    # ================================ WEIGHTS GRADIENTS ==============================================\n",
    "    # dL/dw_hidden2_hidden3 = dL/da_hidden2_hidden3 * da_hidden2_hidden3/dz_hidden2_hidden3 * dz_hidden2_hidden3/dw_hidden2_hidden3\n",
    "    # dL/da_hidden2_hidden3 = dL/dY_pred * dY_pred/dz_hidden3_output * dz_hidden3_output/da_hidden2_hidden3\n",
    "    # da_hidden2_hidden3/dz_hidden2_hidden3 = a_hidden2_hidden3 * (1-a_hidden2_hidden3)\n",
    "    # dz_hidden2_hidden3/dw_hidden2_hidden3 = a_hidden1_hidden2\n",
    "\n",
    "    # dL/da_hidden2_hidden3 = dL/dY_pred * dY_pred/dz_hidden3_output * dz_hidden3_output/da_hidden2_hidden3\n",
    "    # dL/dz_hidden3_output = dL/dY_pred * dY_pred/dz_hidden3_output\n",
    "\n",
    "    dz_hidden3_output_da_hidden2_hidden3 = w_hidden3_output # (4,1)\n",
    "    dL_da_hidden2_hidden3 = dL_dz_hidden3_output @ dz_hidden3_output_da_hidden2_hidden3.T # (1,4)\n",
    "\n",
    "    # da_hidden2_hidden3/dz_hidden2_hidden3 = a_hidden2_hidden3 * (1-a_hidden2_hidden3)\n",
    "    da_hidden2_hidden3_dz_hidden2_hidden3 = a_hidden2_hidden3 * (1-a_hidden2_hidden3) # (1,4)\n",
    "\n",
    "    # dz_hidden2_hidden3/dw_hidden2_hidden3\n",
    "    dz_hidden2_hidden3_dw_hidden2_hidden3 = a_hidden1_hidden2 # (1,8)\n",
    "\n",
    "    # dL/dz_hidden2_hidden3 = dL/da_hidden2_hidden3 * da_hidden2_hidden3/dz_hidden2_hidden3\n",
    "    dL_dz_hidden2_hidden3 = dL_da_hidden2_hidden3 * da_hidden2_hidden3_dz_hidden2_hidden3 # (1,4)\n",
    "\n",
    "    # dL/dw_hidden2_hidden3 = dL/dz_hidden2_hidden3 * dz_hidden2_hidden3/dw_hidden2_hidden3\n",
    "    dL_dw_hidden2_hidden3 = dz_hidden2_hidden3_dw_hidden2_hidden3.T @ dL_dz_hidden2_hidden3 # (8,4)\n",
    "\n",
    "\n",
    "    # ================================ BIAS GRADIENTS ==============================================\n",
    "    # dL/db_hidden2_hidden3  = dL/dz_hidden2_hidden3 * dz_hidden2_hidden3/db_hidden2_hidden3\n",
    "    dz_hidden2_hidden3_db_hidden2_hidden3 = 1\n",
    "    dL_db_hidden2_hidden3 = dL_dz_hidden2_hidden3 * dz_hidden2_hidden3_db_hidden2_hidden3 # (1,4)\n",
    "\n",
    "\n",
    "\n",
    "    # Hidden Layer 2 -> Hidden Layer 1 \n",
    "    # ================================ WEIGHTS GRADIENTS ==============================================\n",
    "    # dL/dw_hidden1_hidden2 = dL/da_hidden1_hidden2 * da_hidden1_hidden2/dz_hidden1_hidden2 * dz_hidden1_hidden2/dw_hidden1_hidden2\n",
    "    # dL/da_hidden1_hidden2 = dL/da_hidden2_hidden3 * da_hidden2_hidden3/dz_hidden2_hidden3 * dz_hidden2_hidden3/da_hidden1_hidden2\n",
    "    # da_hidden1_hidden2/dz_hidden1_hidden2 = a_hidden1_hidden2 * (1-a_hidden1_hidden2)\n",
    "    # dz_hidden1_hidden2/dw_hidden1_hidden2 = a_input_hidden1\n",
    "\n",
    "    # dL/da_hidden1_hidden2 = dL/da_hidden2_hidden3 * da_hidden2_hidden3/dz_hidden2_hidden3 * dz_hidden2_hidden3/da_hidden1_hidden2\n",
    "    # dL/dz_hidden2_hidden3 = dL/da_hidden2_hidden3 * da_hidden2_hidden3/dz_hidden2_hidden3\n",
    "\n",
    "    dz_hidden2_hidden3_da_hidden1_hidden2 = w_hidden2_hidden3 # (8,4)\n",
    "    dL_da_hidden1_hidden2  = dL_dz_hidden2_hidden3 @ dz_hidden2_hidden3_da_hidden1_hidden2.T # (1,8)\n",
    "\n",
    "    # da_hidden1_hidden2/dz_hidden1_hidden2 = a_hidden1_hidden2 * (1-a_hidden1_hidden2)\n",
    "    da_hidden1_hidden2_dz_hidden1_hidden2 = a_hidden1_hidden2 * (1-a_hidden1_hidden2)  # (1,8)\n",
    "\n",
    "    # dz_hidden1_hidden2/dw_hidden1_hidden2 = a_input_hidden1\n",
    "    dz_hidden1_hidden2_dw_hidden1_hidden2 = a_input_hidden1 # (1,16)\n",
    "\n",
    "    # dL/dz_hidden1_hidden2 = dL/da_hidden1_hidden2 * da_hidden1_hidden2/dz_hidden1_hidden2\n",
    "    dL_dz_hidden1_hidden2 = dL_da_hidden1_hidden2 * da_hidden1_hidden2_dz_hidden1_hidden2 # (1,8)\n",
    "\n",
    "    # dL/dw_hidden1_hidden2 = dL/da_hidden1_hidden2 * da_hidden1_hidden2/dz_hidden1_hidden2 * dz_hidden1_hidden2/dw_hidden1_hidden2\n",
    "    dL_dw_hidden1_hidden2 = dz_hidden1_hidden2_dw_hidden1_hidden2.T @ dL_dz_hidden1_hidden2 # (16,8)\n",
    "\n",
    "\n",
    "    # ================================ BIAS GRADIENTS ==============================================\n",
    "    # dL/db_hidden1_hidden2 = dL/dz_hidden1_hidden2 * dz_hidden1_hidden2/db_hidden1_hidden2\n",
    "    dz_hidden1_hidden2_db_hidden1_hidden2 = 1\n",
    "    dL_db_hidden1_hidden2 = dL_dz_hidden1_hidden2 * dz_hidden1_hidden2_db_hidden1_hidden2 # (1,8)\n",
    "\n",
    "\n",
    "\n",
    "    # Hidden Layer 1 -> Input Layer \n",
    "    # ================================ WEIGHTS GRADIENTS ===========================================\n",
    "    # dL/dw_input_hidden1 = dL/da_input_hidden1 * da_input_hidden1/dz_input_hidden1 * dz_input_hidden1/dw_input_hidden1\n",
    "    # dL/da_input_hidden1 = dL/da_hidden1_hidde2 * da_hidden1_hidden2/dz_hidden1_hidden2 * dz_hidden1_hidden2/da_input_hidden1\n",
    "    # da_input_hidden1/dz_input_hidden1 = a_input_hidden1 * (1 - a_input_hidden1)\n",
    "    # dz_input_hidden1/dw_input_hidden1 = X\n",
    "\n",
    "    # dL/da_input_hidden1 = dL/da_hidden1_hidde2 * da_hidden1_hidden2/dz_hidden1_hidden2 * dz_hidden1_hidden2/da_input_hidden1\n",
    "    # dL/dz_hidden1_hidden2 = dL/da_hidden1_hidde2 * da_hidden1_hidden2/dz_hidden1_hidden2 # (1,8)\n",
    "    dz_hidden1_hidden2_da_input_hidden1 = w_hidden1_hidden2 # (16,8)\n",
    "    dL_da_input_hidden1 = dL_dz_hidden1_hidden2 @ dz_hidden1_hidden2_da_input_hidden1.T # (1,16)\n",
    "\n",
    "    # da_input_hidden1/dz_input_hidden1 = a_input_hidden1 * (1 - a_input_hidden1)\n",
    "    da_input_hidden1_dz_input_hidden1 = a_input_hidden1 * (1-a_input_hidden1) # (1,16)\n",
    "\n",
    "    # dL/dz_input_hidden1 = dL/da_input_hidden1 * da_input_hidden1/dz_input_hidden1\n",
    "    dL_dz_input_hidden1 = dL_da_input_hidden1 * da_input_hidden1_dz_input_hidden1 # (1,16)\n",
    "\n",
    "    # dz_input_hidden1/dw_input_hidden1 = X\n",
    "    dz_input_hidden1_dw_input_hidden1 = X # (1,1)\n",
    "\n",
    "    # dL/dw_input_hidden1 = dL/dz_input_hidden1 * dz_input_hidden1/dw_input_hidden1\n",
    "    dL_dw_input_hidden1 = dz_input_hidden1_dw_input_hidden1 @ dL_dz_input_hidden1 # (1,16)\n",
    "\n",
    "\n",
    "    # ================================ BIAS GRADIENTS ==============================================\n",
    "    # dL/db_input_hidden1 = dL/dz_input_hidden1 * dz_input_hidden1/db_input_hidden1\n",
    "    # dz_input_hidden1/db_input_hidden1 = 1\n",
    "    dz_input_hidden1_db_input_hidden1 = 1\n",
    "    dL_db_input_hidden1 = dL_dz_input_hidden1 * dz_input_hidden1_db_input_hidden1 # (1,16)\n",
    "\n",
    "\n",
    "\n",
    "    # ==================================== WEIGHTS, BIAS UPDATION ========================================\n",
    "    # Output Layer -> Hidden Layer 3\n",
    "    w_hidden3_output -= LR*dL_dw_hidden3_output\n",
    "    b_hidden3_output -= LR*dL_db_hidden3_output\n",
    "\n",
    "    # Hidden Layer 3 -> Hidden Layer 2\n",
    "    w_hidden2_hidden3 -= LR*dL_dw_hidden2_hidden3\n",
    "    b_hidden2_hidden3 -= LR*dL_db_hidden2_hidden3\n",
    "\n",
    "    # Hidden Layer 2 -> Hidden Layer 1\n",
    "    w_hidden1_hidden2 -= LR*dL_dw_hidden1_hidden2\n",
    "    b_hidden1_hidden2 -= LR*dL_db_hidden1_hidden2\n",
    "\n",
    "    # Hidden Layer 1 -> Input Layer\n",
    "    w_input_hidden1 -= LR*dL_dw_input_hidden1\n",
    "    b_input_hidden1 -= LR*dL_db_input_hidden1\n",
    "\n",
    "\n",
    "    if (epoch+1) %100 == 0:\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1}| Loss : {L.item():.6f} | Y_pred : {Y_pred.item():.6f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
